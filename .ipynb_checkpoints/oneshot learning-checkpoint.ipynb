{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/asmaa/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io as io\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "a function that loads the images locations and labels.<br>\n",
    "input: the data path.<br>\n",
    "output:<br>\n",
    "&emsp;&emsp;dataHiero -> a dataframe with index= location of images and label= their labels <br>\n",
    "&emsp;&emsp;img_groups -> a dictionary in the shape of { \"label\" : [array of locations of images labeled with this label] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../GlyphDataset/Dataset/Manual/Preprocessed/\"\n",
    "\n",
    "def loadData(folderPictures=path):\n",
    "    \n",
    "    folders=next(os.walk(folderPictures))[1]\n",
    "    img_groups = {}\n",
    "    img_list={}\n",
    "\n",
    "    for folder in folders:\n",
    "        for img_file in os.listdir(folderPictures+folder):\n",
    "            name, \n",
    "            label = img_file.strip('.png').split(\"_\")\n",
    "            \n",
    "            \n",
    "            # One image per class\n",
    "\n",
    "            #if label not in img_groups.keys():\n",
    "            #    img_groups[label] = [folder + \"_\" + name]\n",
    "\n",
    "\n",
    "            # Multiple images per class\n",
    "\n",
    "            if label in img_groups.keys():\n",
    "                img_groups[label].append(folder+\"_\"+name)\n",
    "            else:\n",
    "                img_groups[label] = [folder+\"_\"+name]\n",
    "\n",
    "            img_list[folder+\"_\"+name]=[label]\n",
    "\n",
    "\n",
    "    # Remove class with only one hieroglyph\n",
    "\n",
    "\n",
    "    for k,v in list(img_groups.items()):\n",
    "        if len(v)==1: del img_groups[k]\n",
    "\n",
    "    # Extract only N hieroglyph classes randomly\n",
    "\n",
    "    nclass = len(img_groups.keys())\n",
    "\n",
    "    list_of_class = random.sample(list(img_groups.keys()), nclass)\n",
    "#     print(list_of_class)\n",
    "\n",
    "    short_dico = {x: img_groups[x] for x in list_of_class if x in img_groups}\n",
    "\n",
    "    dataHiero=pd.DataFrame.from_dict(img_list,orient='index')\n",
    "    dataHiero.columns = [\"label\"]\n",
    "    dataHiero = dataHiero[dataHiero.label != 'UNKNOWN']\n",
    "\n",
    "    dataHiero = dataHiero.loc[dataHiero['label'].isin(short_dico)]\n",
    "\n",
    "\n",
    "    dataHiero.reset_index(level=0, inplace=True)\n",
    "\n",
    "    return dataHiero,img_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a function that takes the image groups and load those images<br>\n",
    "input: img_proups dictionary<br>\n",
    "output:<br>\n",
    "&emsp;&emsp;X -> np array of the images<br>\n",
    "&emsp;&emsp;y -> np array of labels<br>\n",
    "&emsp;&emsp;glyph_sizes -> a dictionary in the form of {'label' : (starting index, ending index in X and y)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_groups,path):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    glyph_sizes={}\n",
    "    low=0\n",
    "    for glyph in img_groups:\n",
    "        category_images=[]\n",
    "        high=low\n",
    "        for img_path in img_groups[glyph] :\n",
    "            folder,name = img_path.split('_')\n",
    "            image = io.imread(path+folder+'/'+name+'_'+glyph+'.png')\n",
    "            X.append(image)\n",
    "            y.append(glyph)\n",
    "            high+=1\n",
    "#         X.append(np.array(category_images))\n",
    "        glyph_sizes[glyph]=(low,high-1)\n",
    "        low=high\n",
    "        \n",
    "    return np.array(X),np.array(y).reshape((-1,1)),glyph_sizes\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39_390115</td>\n",
       "      <td>D21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39_390082</td>\n",
       "      <td>M17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39_390292</td>\n",
       "      <td>V31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39_390375</td>\n",
       "      <td>U15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39_390175</td>\n",
       "      <td>D35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index label\n",
       "0  39_390115   D21\n",
       "1  39_390082   M17\n",
       "2  39_390292   V31\n",
       "3  39_390375   U15\n",
       "4  39_390175   D35"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataHiero,img_groups=loadData(folderPictures=path)\n",
    "dataHiero.head()\n",
    "# img_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,sizes=read_images(img_groups,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2921, 1)\n",
      "(2921, 75, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "sizes['D21'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the images into a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train val split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sizes(X,Y):\n",
    "    sizes={}\n",
    "    for i ,(x,y) in enumerate(zip(X,Y)):\n",
    "#         print(i,x,y)\n",
    "        if y[0] in sizes:\n",
    "            sizes[y[0]].append(i)\n",
    "        else:\n",
    "            sizes[y[0]]=[i]\n",
    "    return sizes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes=get_sizes(X_train,y_train)\n",
    "X=X_train\n",
    "y=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data as pickle\n",
    "with open(\"train.pickle\", \"wb\") as f:\n",
    "    pickle.dump((X,y,sizes),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_val=get_sizes(X_test,y_test)\n",
    "Xval=X_test\n",
    "yval=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data as pickle\n",
    "with open(\"test.pickle\", \"wb\") as f:\n",
    "    pickle.dump((Xval,yval,sizes_val),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving data as pickle\n",
    "# with open(\"test.pickle\", \"wb\") as f:\n",
    "#     pickle.dump((Xval,yval,sizes_val),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the training tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('./', \"train.pickle\"), \"rb\") as f:\n",
    "    (X,y,sizes) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('./', \"test.pickle\"), \"rb\") as f:\n",
    "    (Xval,yval,sizes_val) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_siamese_model_2(input_shape):\n",
    "#     \"\"\"\n",
    "#         Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Define the tensors for the two input images\n",
    "#     left_input = Input(input_shape)\n",
    "#     right_input = Input(input_shape)\n",
    "    \n",
    "#     # Convolutional Neural Network\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(64, (3,3),strides=(2, 2), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "#     model.add(MaxPooling2D((2, 2), strides=2))\n",
    "#     model.add(Conv2D(64, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "#     model.add(MaxPooling2D((2, 2), strides=2))\n",
    "#     model.add(Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "# #     model.add(MaxPooling2D())\n",
    "# #     model.add(Conv2D(256, (4,4), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(4096, activation='sigmoid',\n",
    "#                    kernel_regularizer=l2(1e-3)))\n",
    "    \n",
    "#     # Generate the encodings (feature vectors) for the two images\n",
    "#     encoded_l = model(left_input)\n",
    "#     encoded_r = model(right_input)\n",
    "    \n",
    "#     # Add a customized layer to compute the absolute difference between the encodings\n",
    "#     L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#     L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "#     # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "#     prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "#     # Connect the inputs with the outputs\n",
    "#     siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "#     # return the model\n",
    "#     return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_2 = get_siamese_model_2((75, 50, 1))\n",
    "# model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr = 0.001)\n",
    "# model_2.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transfer_model(input_shape):\n",
    "#     \"\"\"\n",
    "#         Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Define the tensors for the two input images\n",
    "#     left_input = Input(input_shape)\n",
    "#     right_input = Input(input_shape)\n",
    "    \n",
    "#     #Import inception model for transfer learning without output layers\n",
    "#     base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = input_shape)\n",
    "    \n",
    "    \n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     # let's add a fully-connected layer\n",
    "#     x = Dense(1024, activation='relu')(x)\n",
    "#     # and a logistic layer -- let's say we have 200 classes\n",
    "#     model= Dense(200, activation='softmax')(x)\n",
    "    \n",
    "#     # this is the model we will train\n",
    "# #     model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "    \n",
    "#     # Generate the encodings (feature vectors) for the two images\n",
    "#     encoded_l = model(left_input)\n",
    "#     encoded_r = model(right_input)\n",
    "    \n",
    "#     # Add a customized layer to compute the absolute difference between the encodings\n",
    "#     L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#     L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "#     # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "#     prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "#     # Connect the inputs with the outputs\n",
    "#     model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "#     for layer in model.layers[:249]:\n",
    "#        layer.trainable = False\n",
    "#     for layer in model.layers[249:]:\n",
    "#        layer.trainable = True\n",
    "    \n",
    "#     # return the model\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception_model = transfer_model((75, 50, 1))\n",
    "# inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3)))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/asmaa/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75, 50, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 75, 50, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         4891712     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,895,809\n",
      "Trainable params: 4,895,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((75, 50, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a function that create pairs of images with y= 1 if they are similar and 0 if they are different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a function to predict which glyph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glyphlist(X,sizes):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    _,w,h=X.shape\n",
    "    for glyph in sizes:\n",
    "        index=sizes[glyph][0]\n",
    "        images.append(X[index].reshape( w , h, 1))\n",
    "        labels.append(glyph)\n",
    "    return np.asarray(images), np.asarray(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_img, anchor_label=create_glyphlist(X,sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichGlyph_pair(image,anchor_img,anchor_label):\n",
    "    N,w,h,_=anchor_img.shape\n",
    "#     pairs=[np.zeros((N, w, h,1)) for i in range(2)]\n",
    "    \n",
    "    test_image= np.asarray([image]*N).reshape(N, w, h,1)\n",
    "    \n",
    "    anchor_label, test_image, anchor_img = shuffle(anchor_label, test_image, anchor_img)\n",
    "#     pairs = [test_image,anchor_img]\n",
    "    \n",
    "    return test_image, anchor_img, anchor_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichGlyph(model,image,anchor_img,anchor_label):\n",
    "    test_image,anchor_img,targets = whichGlyph_pair(image,anchor_img,anchor_label)\n",
    "    probs = model.predict([test_image,anchor_img])\n",
    "    return probs,anchor_img,targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def whichGlyph(model,image,anchor_img,anchor_label):\n",
    "#     test_image,anchor_img,targets = whichGlyph_pair(image,anchor_img,anchor_label)\n",
    "#     probs=[]\n",
    "#     for i in range(0,len(targets),2):\n",
    "#         pair=[[test_image[i],test_image[i+1]],[anchor_img[i],anchor_img[i+1]]]\n",
    "#         pred=model.predict(pair)\n",
    "#         for p in pred:\n",
    "#             probs.append(p)\n",
    "        \n",
    "#     return probs,anchor_img,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPairs(X,y,sizes,batch_size):\n",
    "    ##create a batch with half it's size are similar glyphs and the other half are different.\n",
    "    n=0\n",
    "    i=0\n",
    "    \n",
    "    label=[]\n",
    "    _,w,h=X.shape\n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "#     pairs=[np.zeros((batch_size, w, h,1)) for i in range(2)]\n",
    "    input1=np.zeros((batch_size, w, h,1))\n",
    "    input2=np.zeros((batch_size, w, h,1))\n",
    "    \n",
    "    while n < batch_size:\n",
    "        random_key1=random.choice(list(sizes))\n",
    "#         low=sizes[random_key1][0]\n",
    "#         high=sizes[random_key1][1]\n",
    "        index1, index3 = np.random.choice(sizes[random_key1], size=2)\n",
    "        index2 = np.random.choice(sizes[random_key1])\n",
    "        random_key2=random.choice(list(sizes))\n",
    "        \n",
    "        while random_key2 == random_key1:\n",
    "            random_key2=random.choice(list(sizes))\n",
    "            \n",
    "#         low=sizes[random_key2][0]\n",
    "#         high=sizes[random_key2][1]\n",
    "        index4=np.random.choice(sizes[random_key2])\n",
    "        n += 2\n",
    "        # appending images 1 and 3 into input1 and input2 corresponding to y=1 \n",
    "        #and images 2 and 4 corresponding to y=0\n",
    "    \n",
    "        input1[i,:,:,:] = X[index1].reshape( w , h, 1)\n",
    "        input1[i+1,:,:,:] = X[index2].reshape(w, h, 1)\n",
    "        input2[i,:,:,:] = X[index3].reshape(w, h, 1)\n",
    "        input2[i+1,:,:,:] = X[index4].reshape(w, h, 1)\n",
    "        i += 2\n",
    "#         input1+=[X[index1],X[index2]]\n",
    "#         input2+=[X[index3],X[index4]]\n",
    "        label+=[1,0]\n",
    "        \n",
    "#         print(index1,index2,index3,index4)\n",
    "#         print(y[index1],y[index2],y[index3],y[index4])\n",
    "#         print(random_key1,random_key2)\n",
    "    input1,input2,label = shuffle(input1,input2,label)\n",
    "    pairs=[input1,input2]\n",
    "    \n",
    "    return pairs,label\n",
    "pairs,label=createPairs(X,y,sizes,32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs[1].shape\n",
    "# label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a fn that creates a N-way one shot learning task where it create pairs with the wanted image and N-1 different ones and 1 similar one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oneshot_task(X,y,sizes,N):\n",
    "    _,w,h=X.shape\n",
    "    pairs=[np.zeros((N, w, h,1)) for i in range(2)]\n",
    "    \n",
    "    true_key=random.choice(list(sizes))\n",
    "#     low=sizes[true_key][0]\n",
    "#     high=sizes[true_key][1]\n",
    "    \n",
    "    index=np.random.choice(sizes[true_key])\n",
    "    index2=np.random.choice(sizes[true_key])\n",
    "    \n",
    "    test_image= np.asarray([X[index]]*N).reshape(N, w, h,1)\n",
    "#     print(X.shape)\n",
    "    X_diff= np.delete(X,sizes[true_key],axis=0)\n",
    "#     print(X_diff.shape)\n",
    "    indices= np.random.choice(range(0, len(X_diff)), size = N-1)\n",
    "    \n",
    "    support_set=X_diff[indices,:,:]\n",
    "    ##!!! adding the similar image to the start of the array is not working!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "#     print(support_set.shape)\n",
    "#     support_set = [ X[index2] ] + support_set\n",
    "    support_set=np.insert(support_set,0,X[index2],axis=0)\n",
    "#     print(support_set.shape)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    support_set=support_set.reshape(N,w,h,1)\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "\n",
    "    return pairs, targets\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 75, 50, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp,tt=make_oneshot_task(Xval,yval,sizes_val,20) \n",
    "pp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 75, 50, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.imshow(pairs[0][0])\n",
    "pairs[1].shape\n",
    "# len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_oneshot(model,X,y,sizes, N, k, s = \"val\", verbose = 0):\n",
    "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(X,y,sizes,N)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "    percent_correct = (100.0 * n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 20000 # No. of training iterations 20000\n",
    "N_way = 20 # how many classes for testing one-shot tasks\n",
    "n_val = 250 # how many one-shot tasks to validate on\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './weights/'\n",
    "model_2_path= './weights_model_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2921, 75, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "WARNING:tensorflow:From /home/asmaa/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 1.64547967116038 mins\n",
      "Train Loss: 1.3820552825927734\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 28.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 28.8, previous best: -1\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 400 iterations: 3.774888304869334 mins\n",
      "Train Loss: 0.9540039300918579\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 28.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 600 iterations: 5.877415760358175 mins\n",
      "Train Loss: 0.7964816093444824\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 42.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 42.4, previous best: 28.8\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 800 iterations: 8.040658072630565 mins\n",
      "Train Loss: 0.7264848947525024\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 43.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 43.2, previous best: 42.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1000 iterations: 10.259224728743236 mins\n",
      "Train Loss: 0.7388213276863098\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 47.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 47.2, previous best: 43.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1200 iterations: 12.469716453552246 mins\n",
      "Train Loss: 0.6140071749687195\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 44.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1400 iterations: 14.68959150314331 mins\n",
      "Train Loss: 0.5143598318099976\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 50.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 50.8, previous best: 47.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1600 iterations: 16.92307864824931 mins\n",
      "Train Loss: 0.6457452178001404\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 50.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 50.8, previous best: 50.8\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1800 iterations: 19.144837665557862 mins\n",
      "Train Loss: 0.5143750905990601\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 52.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 52.8, previous best: 50.8\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2000 iterations: 21.374476746718088 mins\n",
      "Train Loss: 0.5058580636978149\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 55.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 55.2, previous best: 52.8\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2200 iterations: 23.556224211057028 mins\n",
      "Train Loss: 0.4663999080657959\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 60.0, previous best: 55.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2400 iterations: 25.662189841270447 mins\n",
      "Train Loss: 0.447493314743042\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 59.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2600 iterations: 27.768596080938973 mins\n",
      "Train Loss: 0.3877614140510559\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 52.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2800 iterations: 29.92743991613388 mins\n",
      "Train Loss: 0.4304414391517639\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3000 iterations: 32.0168666323026 mins\n",
      "Train Loss: 0.3311038613319397\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 57.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3200 iterations: 34.07688961029053 mins\n",
      "Train Loss: 0.38685569167137146\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 63.6% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 63.6, previous best: 60.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3400 iterations: 36.195506934324904 mins\n",
      "Train Loss: 0.34651926159858704\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 66.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 66.4, previous best: 63.6\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3600 iterations: 38.32064877351125 mins\n",
      "Train Loss: 0.3214077949523926\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 49.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3800 iterations: 40.46445753177007 mins\n",
      "Train Loss: 0.26587051153182983\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4000 iterations: 42.579149119059245 mins\n",
      "Train Loss: 0.41486823558807373\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4200 iterations: 44.929688239097594 mins\n",
      "Train Loss: 0.2534094452857971\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4400 iterations: 47.401313285032906 mins\n",
      "Train Loss: 0.24917569756507874\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4600 iterations: 49.52969499826431 mins\n",
      "Train Loss: 0.2259642481803894\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 53.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4800 iterations: 51.88081361452738 mins\n",
      "Train Loss: 0.3073728084564209\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 49.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5000 iterations: 54.123530276616414 mins\n",
      "Train Loss: 0.28598830103874207\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5200 iterations: 56.52320730288823 mins\n",
      "Train Loss: 0.2297375202178955\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 50.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5400 iterations: 58.728335253397624 mins\n",
      "Train Loss: 0.28741535544395447\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 55.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5600 iterations: 61.34792644580205 mins\n",
      "Train Loss: 0.209148108959198\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 73.2, previous best: 66.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5800 iterations: 63.97915796041489 mins\n",
      "Train Loss: 0.25610068440437317\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 66.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6000 iterations: 66.52305869658788 mins\n",
      "Train Loss: 0.28194326162338257\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6200 iterations: 68.90006783008576 mins\n",
      "Train Loss: 0.19676166772842407\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6400 iterations: 71.42280164957046 mins\n",
      "Train Loss: 0.18337151408195496\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 52.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6600 iterations: 73.97007793585459 mins\n",
      "Train Loss: 0.3503762185573578\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.8% 20 way one-shot learning accuracy \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6800 iterations: 76.12774416605632 mins\n",
      "Train Loss: 0.13866177201271057\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7000 iterations: 78.42596634229024 mins\n",
      "Train Loss: 0.15529651939868927\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7200 iterations: 81.15371625820795 mins\n",
      "Train Loss: 0.22774484753608704\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7400 iterations: 83.84785331090292 mins\n",
      "Train Loss: 0.17660848796367645\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7600 iterations: 86.36416828234991 mins\n",
      "Train Loss: 0.18757598102092743\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7800 iterations: 89.02609171470006 mins\n",
      "Train Loss: 0.15024018287658691\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 69.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8000 iterations: 91.50690175294876 mins\n",
      "Train Loss: 0.18684597313404083\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8200 iterations: 94.30755095481872 mins\n",
      "Train Loss: 0.20000925660133362\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 76.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 76.0, previous best: 73.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8400 iterations: 96.89331412712733 mins\n",
      "Train Loss: 0.20201408863067627\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.4% 20 way one-shot learning accuracy \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1e7966f75afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreatePairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n ------------- \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs,targets) = createPairs(X,y,sizes,batch_size)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model,Xval,yval,sizes_val, N_way, n_val, verbose=True)\n",
    "        model.save_weights(os.path.join(model_2_path, 'weights.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Starting training process!\")\n",
    "# print(\"-------------------------------------\")\n",
    "# t_start = time.time()\n",
    "# for i in range(1, n_iter+1):\n",
    "#     (inputs,targets) = createPairs(X,y,sizes,batch_size)\n",
    "#     loss = model.train_on_batch(inputs, targets)\n",
    "#     if i % evaluate_every == 0:\n",
    "#         print(\"\\n ------------- \\n\")\n",
    "#         print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "#         print(\"Train Loss: {0}\".format(loss)) \n",
    "#         val_acc = test_oneshot(model,Xval,yval,sizes_val, N_way, n_val, verbose=True)\n",
    "#         model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "#         if val_acc >= best:\n",
    "#             print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "#             best = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading model from weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path+'weights.20000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(N,Xval,yval,anchor_img,anchor_label,model):\n",
    "    count_first=0\n",
    "    count_first3=0\n",
    "    for i in range(N):\n",
    "        ind=random.choice(range(yval.shape[0]))\n",
    "        predicted,anchor_imgs,targets=whichGlyph(model,Xval[ind],anchor_img,anchor_label)\n",
    "        sort_index = np.argsort(np.asarray(predicted).reshape(130,))\n",
    "        if targets[sort_index[-1]] == yval[ind][0]:\n",
    "            count_first+=1\n",
    "        if yval[ind][0] in targets[sort_index[127:]]:\n",
    "            count_first3+=1\n",
    "    accuracy_first=count_first/N\n",
    "    accuracy_first3=count_first3/N\n",
    "    \n",
    "    return accuracy_first, accuracy_first3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.564, 0.736)\n",
      "accuracy fn took 2.4821476976076764 mins\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "acc1,acc3=calc_accuracy(250,Xval,yval,anchor_img,anchor_label,model)\n",
    "print(f'testing:\\nfound first accuracy = {acc1} , first 3 accuracy = {acc3} ')\n",
    "print(\"accuracy fn took {0} mins\".format((time.time()-t_start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.832, 0.968)\n",
      "accuracy fn took 2.417163900534312 mins\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "acc1,acc3=calc_accuracy(250,X,y,anchor_img,anchor_label,model)\n",
    "print(f'training:\\nfound first accuracy = {acc1} , first 3 accuracy = {acc3} ')\n",
    "print(\"accuracy fn took {0} mins\".format((time.time()-t_start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0)\n",
      "accuracy fn took 0.5639333724975586 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(calc_accuracy(1,Xval,yval,anchor_img,anchor_label,model))\n",
    "print(\"accuracy fn took {0} sec\".format((time.time()-t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
