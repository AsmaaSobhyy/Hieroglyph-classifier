{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io as io\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../GlyphDataset/Dataset/Manual/Preprocessed/\"\n",
    "\n",
    "def loadData(folderPictures=path):\n",
    "    \n",
    "    folders=next(os.walk(folderPictures))[1]\n",
    "    img_groups = {}\n",
    "    img_list={}\n",
    "\n",
    "    for folder in folders:\n",
    "        for img_file in os.listdir(folderPictures+folder):\n",
    "            name, label = img_file.strip('.png').split(\"_\")\n",
    "            \n",
    "            \n",
    "            # One image per class\n",
    "\n",
    "            #if label not in img_groups.keys():\n",
    "            #    img_groups[label] = [folder + \"_\" + name]\n",
    "\n",
    "\n",
    "            # Multiple images per class\n",
    "\n",
    "            if label in img_groups.keys():\n",
    "                img_groups[label].append(folder+\"_\"+name)\n",
    "            else:\n",
    "                img_groups[label] = [folder+\"_\"+name]\n",
    "\n",
    "            img_list[folder+\"_\"+name]=[label]\n",
    "\n",
    "\n",
    "    # Remove class with only one hieroglyph\n",
    "\n",
    "\n",
    "    for k,v in list(img_groups.items()):\n",
    "        if len(v)==1: del img_groups[k]\n",
    "\n",
    "    # Extract only N hieroglyph classes randomly\n",
    "\n",
    "    nclass = len(img_groups.keys())\n",
    "\n",
    "    list_of_class = random.sample(list(img_groups.keys()), nclass)\n",
    "#     print(list_of_class)\n",
    "\n",
    "    short_dico = {x: img_groups[x] for x in list_of_class if x in img_groups}\n",
    "\n",
    "    dataHiero=pd.DataFrame.from_dict(img_list,orient='index')\n",
    "    dataHiero.columns = [\"label\"]\n",
    "    dataHiero = dataHiero[dataHiero.label != 'UNKNOWN']\n",
    "\n",
    "    dataHiero = dataHiero.loc[dataHiero['label'].isin(short_dico)]\n",
    "\n",
    "\n",
    "    dataHiero.reset_index(level=0, inplace=True)\n",
    "\n",
    "    return dataHiero,img_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_groups,path):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    glyph_sizes={}\n",
    "    low=0\n",
    "    for glyph in img_groups:\n",
    "        category_images=[]\n",
    "        high=low\n",
    "        for img_path in img_groups[glyph] :\n",
    "            folder,name = img_path.split('_')\n",
    "            image = io.imread(path+folder+'/'+name+'_'+glyph+'.png')\n",
    "            X.append(image)\n",
    "            y.append(glyph)\n",
    "            high+=1\n",
    "#         X.append(np.array(category_images))\n",
    "        glyph_sizes[glyph]=(low,high-1)\n",
    "        low=high\n",
    "        \n",
    "    return np.array(X),np.array(y).reshape((-1,1)),glyph_sizes\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39_390115</td>\n",
       "      <td>D21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39_390082</td>\n",
       "      <td>M17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39_390292</td>\n",
       "      <td>V31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39_390375</td>\n",
       "      <td>U15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39_390175</td>\n",
       "      <td>D35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index label\n",
       "0  39_390115   D21\n",
       "1  39_390082   M17\n",
       "2  39_390292   V31\n",
       "3  39_390375   U15\n",
       "4  39_390175   D35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataHiero,img_groups=loadData(folderPictures=path)\n",
    "dataHiero.head()\n",
    "# img_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,sizes=read_images(img_groups,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3711, 1)\n",
      "(3711, 75, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "sizes['D21'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data as pickle\n",
    "with open(\"train.pickle\", \"wb\") as f:\n",
    "    pickle.dump((X,y,sizes),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hieroRecoModel_offline(input_shape):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # First Block\n",
    "    X = Conv2D(64, (3, 3), strides=(2, 2), name='conv1')(X)\n",
    "    X = BatchNormalization(axis=1, name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=2)(X)\n",
    "\n",
    "    X = Conv2D(64, (3, 3))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=2)(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, name='dense_layer')(X)\n",
    "\n",
    "    # L2 normalization\n",
    "    X = Lambda(lambda x: K.l2_normalize(x, axis=1))(X)\n",
    "\n",
    "    features = Model(X_input, X, name=\"features\")\n",
    "\n",
    "    # Inputs of the siamese network\n",
    "\n",
    "#     anchor = Input(shape=input_shape)\n",
    "#     positive = Input(shape=input_shape)\n",
    "#     negative = Input(shape=input_shape)\n",
    "\n",
    "#     # Embedding Features of input\n",
    "\n",
    "#     anchor_features = features(anchor)\n",
    "#     pos_features = features(positive)\n",
    "#     neg_features = features(negative)\n",
    "\n",
    "#     input_triplet = [anchor, positive, negative]\n",
    "#     output_features = [anchor_features, pos_features, neg_features]\n",
    "\n",
    "#     # Define the trainable model\n",
    "#     loss_model = Model(inputs=input_triplet, outputs=output_features,name='loss')\n",
    "#     loss_model.add_loss(K.mean(triplet_loss(output_features)))\n",
    "#     loss_model.compile(loss=None,optimizer='adam')\n",
    "\n",
    "\n",
    "    # Create model instance\n",
    "    #model = Model(inputs=X_input, outputs=X, name='HieroRecoModel_off')\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"features\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 50, 75, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 56, 81, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 27, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 27, 40, 64)        108       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 11, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 128)               327808    \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 365,484\n",
      "Trainable params: 365,430\n",
      "Non-trainable params: 54\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = hieroRecoModel_offline((50, 75, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3)))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 75, 50, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 75, 50, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 4096)         4891712     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 4096)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            4097        lambda_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,895,809\n",
      "Trainable params: 4,895,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((75, 50, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/asmaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPairs(X,y,sizes,batch_size):\n",
    "    ##create a batch with half it's size are similar glyphs and the other half are different.\n",
    "    n=0\n",
    "    i=0\n",
    "#     input1=[]\n",
    "#     input2=[]\n",
    "    label=[]\n",
    "    _,w,h=X.shape\n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs=[np.zeros((batch_size, w, h,1)) for i in range(2)]\n",
    "    \n",
    "    while n < batch_size:\n",
    "        random_key1=random.choice(list(sizes))\n",
    "        low=sizes[random_key1][0]\n",
    "        high=sizes[random_key1][1]\n",
    "        index1, index2, index3=np.random.choice(range(low, high), size=3,replace=True)\n",
    "        random_key2=random.choice(list(sizes))\n",
    "        \n",
    "        while random_key2 == random_key1:\n",
    "            random_key2=random.choice(list(sizes))\n",
    "            \n",
    "        low=sizes[random_key2][0]\n",
    "        high=sizes[random_key2][1]\n",
    "        index4=np.random.choice(range(low,high))\n",
    "        n += 2\n",
    "        # appending images 1 and 3 into input1 and input2 corresponding to y=1 \n",
    "        #and images 2 and 4 corresponding to y=0\n",
    "    \n",
    "        pairs[0][i,:,:,:] = X[index1].reshape( w , h, 1)\n",
    "        pairs[0][i+1,:,:,:] = X[index2].reshape(w, h, 1)\n",
    "        pairs[1][i,:,:,:] = X[index3].reshape(w, h, 1)\n",
    "        pairs[1][i+1,:,:,:] = X[index4].reshape(w, h, 1)\n",
    "        i += 2\n",
    "#         input1+=[X[index1],X[index2]]\n",
    "#         input2+=[X[index3],X[index4]]\n",
    "        label+=[1,0]\n",
    "        \n",
    "#         print(index1,index2,index3,index4)\n",
    "#         print(y[index1],y[index2],y[index3],y[index4])\n",
    "#         print(random_key1,random_key2)\n",
    "    return pairs,label\n",
    "pairs,label=createPairs(X,y,sizes,32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "# # np.delete(mm,range(3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oneshot_task(X,y,sizes,N):\n",
    "    _,w,h=X.shape\n",
    "    pairs=[np.zeros((N, w, h,1)) for i in range(2)]\n",
    "    \n",
    "    true_key=random.choice(list(sizes))\n",
    "    low=sizes[true_key][0]\n",
    "    high=sizes[true_key][1]\n",
    "    \n",
    "    index=np.random.choice(range(low, high))\n",
    "    index2=np.random.choice(range(low, high))\n",
    "    \n",
    "    test_image= np.asarray([X[index]]*N).reshape(N, w, h,1)\n",
    "#     print(X.shape)\n",
    "    X_diff= np.delete(X,range(low,high),axis=0)\n",
    "#     print(X_diff.shape)\n",
    "    indices= np.random.choice(range(0, len(X_diff)), size = N-1)\n",
    "    \n",
    "    support_set=X_diff[indices,:,:]\n",
    "    ##!!! adding the similar image to the start of the array is not working!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "#     print(support_set.shape)\n",
    "#     support_set = [ X[index2] ] + support_set\n",
    "    support_set=np.insert(support_set,0,X[index2],axis=0)\n",
    "#     print(support_set.shape)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    support_set=support_set.reshape(N,w,h,1)\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "\n",
    "    return pairs, targets\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 75, 50, 1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp,tt=make_oneshot_task(Xval,yval,sizes_val,20) \n",
    "pp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 75, 50, 1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.imshow(pairs[0][0])\n",
    "pairs[1].shape\n",
    "# len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "##validation data\n",
    "val_path=\"../GlyphDataset/Dataset/Manual/val/\"\n",
    "dataHiero_val,img_groups_val=loadData(folderPictures=val_path)\n",
    "Xval,yval,sizes_val=read_images(img_groups_val,val_path)\n",
    "pairsval,labelval=createPairs(Xval,yval,sizes_val,32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_oneshot_task(N,X,y):\n",
    "#     \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "#     if s == 'train':\n",
    "#         X = Xtrain\n",
    "#         categories = train_classes\n",
    "#     else:\n",
    "#         X = Xval\n",
    "#         categories = val_classes\n",
    "#     n_classes, n_examples, w, h = X.shape\n",
    "    \n",
    "#     indices = rng.randint(0, n_examples,size=(N,))\n",
    "#  # if no language specified just pick a bunch of random letters\n",
    "#     categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "#     true_category = categories[0]\n",
    "#     ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "#     test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "#     support_set = X[categories,indices,:,:]\n",
    "#     support_set[0,:,:] = X[true_category,ex2]\n",
    "#     support_set = support_set.reshape(N, w, h,1)\n",
    "#     targets = np.zeros((N,))\n",
    "#     targets[0] = 1\n",
    "#     targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "#     pairs = [test_image,support_set]\n",
    "\n",
    "#     return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_oneshot(model,X,y,sizes, N, k, s = \"val\", verbose = 0):\n",
    "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(X,y,sizes,N)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "    percent_correct = (100.0 * n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 20000 # No. of training iterations \n",
    "N_way = 20 # how many classes for testing one-shot tasks\n",
    "n_val = 250 # how many one-shot tasks to validate on\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 1.6976775844891867 mins\n",
      "Train Loss: 0.6553137898445129\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 50.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 50.4, previous best: -1\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 400 iterations: 3.447393794854482 mins\n",
      "Train Loss: 0.4699699282646179\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 62.4, previous best: 50.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 600 iterations: 5.224531070391337 mins\n",
      "Train Loss: 0.4957376718521118\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 53.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 800 iterations: 7.018525993824005 mins\n",
      "Train Loss: 0.5388809442520142\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1000 iterations: 8.963985375563304 mins\n",
      "Train Loss: 0.41554614901542664\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1200 iterations: 10.981147575378419 mins\n",
      "Train Loss: 0.4213007390499115\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1400 iterations: 12.99082218805949 mins\n",
      "Train Loss: 0.3293817639350891\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 50.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1600 iterations: 15.093665262063345 mins\n",
      "Train Loss: 0.3745153844356537\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1800 iterations: 17.40623236099879 mins\n",
      "Train Loss: 0.31516537070274353\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 65.2, previous best: 62.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2000 iterations: 19.636902364095054 mins\n",
      "Train Loss: 0.5409447550773621\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 65.2, previous best: 65.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2200 iterations: 21.816107853253683 mins\n",
      "Train Loss: 0.3580065369606018\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 65.2, previous best: 65.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2400 iterations: 23.866507629553478 mins\n",
      "Train Loss: 0.3101905584335327\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2600 iterations: 26.0350181221962 mins\n",
      "Train Loss: 0.2700621783733368\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2800 iterations: 28.167519040902455 mins\n",
      "Train Loss: 0.3369458317756653\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 55.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3000 iterations: 30.349101134141286 mins\n",
      "Train Loss: 0.30838558077812195\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 57.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3200 iterations: 32.54219081004461 mins\n",
      "Train Loss: 0.24052929878234863\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3400 iterations: 34.72910339832306 mins\n",
      "Train Loss: 0.21244078874588013\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3600 iterations: 36.68741972049077 mins\n",
      "Train Loss: 0.25769472122192383\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3800 iterations: 38.51067964633306 mins\n",
      "Train Loss: 0.29514673352241516\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 57.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4000 iterations: 40.32415243784587 mins\n",
      "Train Loss: 0.289045125246048\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 68.4, previous best: 65.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4200 iterations: 42.14244156678517 mins\n",
      "Train Loss: 0.2629016935825348\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4400 iterations: 43.90029650529225 mins\n",
      "Train Loss: 0.25186872482299805\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4600 iterations: 45.61598150332769 mins\n",
      "Train Loss: 0.27821600437164307\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 70.0, previous best: 68.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4800 iterations: 47.330346862475075 mins\n",
      "Train Loss: 0.2543286681175232\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 66.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5000 iterations: 49.05091619888942 mins\n",
      "Train Loss: 0.17457140982151031\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5200 iterations: 50.79106082518896 mins\n",
      "Train Loss: 0.2576800584793091\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5400 iterations: 52.55703950325648 mins\n",
      "Train Loss: 0.21275484561920166\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 70.8, previous best: 70.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5600 iterations: 54.34937026500702 mins\n",
      "Train Loss: 0.1952342838048935\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 57.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5800 iterations: 56.16029082536697 mins\n",
      "Train Loss: 0.2348695695400238\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6000 iterations: 57.95982848008474 mins\n",
      "Train Loss: 0.20938970148563385\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6200 iterations: 59.806861929098766 mins\n",
      "Train Loss: 0.22667568922042847\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 55.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6400 iterations: 61.65153452555339 mins\n",
      "Train Loss: 0.2855117619037628\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6600 iterations: 63.49023472865422 mins\n",
      "Train Loss: 0.24452830851078033\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6800 iterations: 65.32212901115417 mins\n",
      "Train Loss: 0.17496821284294128\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 66.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7000 iterations: 67.08022383054097 mins\n",
      "Train Loss: 0.17187678813934326\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 61.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7200 iterations: 68.8921886563301 mins\n",
      "Train Loss: 0.38855504989624023\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7400 iterations: 70.6104100783666 mins\n",
      "Train Loss: 0.20513571798801422\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7600 iterations: 72.33518684705099 mins\n",
      "Train Loss: 0.24481472373008728\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 66.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7800 iterations: 74.14398151636124 mins\n",
      "Train Loss: 0.32242095470428467\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8000 iterations: 75.9152165611585 mins\n",
      "Train Loss: 0.16433711349964142\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8200 iterations: 77.71290815671286 mins\n",
      "Train Loss: 0.2656609117984772\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8400 iterations: 79.55126799345017 mins\n",
      "Train Loss: 0.19465994834899902\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 51.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8600 iterations: 81.37999136447907 mins\n",
      "Train Loss: 0.16056275367736816\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 58.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8800 iterations: 83.19836259285609 mins\n",
      "Train Loss: 0.1632191389799118\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9000 iterations: 85.03029737869899 mins\n",
      "Train Loss: 0.16239280998706818\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 71.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 71.2, previous best: 70.8\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9200 iterations: 86.8507894396782 mins\n",
      "Train Loss: 0.18114003539085388\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9400 iterations: 88.69075975020726 mins\n",
      "Train Loss: 0.17084841430187225\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9600 iterations: 90.5240650097529 mins\n",
      "Train Loss: 0.14130659401416779\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9800 iterations: 92.34863593180974 mins\n",
      "Train Loss: 0.18303553760051727\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10000 iterations: 94.1653042157491 mins\n",
      "Train Loss: 0.14455755054950714\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 59.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10200 iterations: 96.01544959545136 mins\n",
      "Train Loss: 0.16141003370285034\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10400 iterations: 97.83990216255188 mins\n",
      "Train Loss: 0.146351620554924\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 59.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10600 iterations: 99.71988937457402 mins\n",
      "Train Loss: 0.11759878695011139\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 72.0, previous best: 71.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10800 iterations: 101.63453021844228 mins\n",
      "Train Loss: 0.12845255434513092\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 71.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11000 iterations: 103.37575763463974 mins\n",
      "Train Loss: 0.18677696585655212\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11200 iterations: 105.11768285433452 mins\n",
      "Train Loss: 0.17363734543323517\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11400 iterations: 106.86322336196899 mins\n",
      "Train Loss: 0.13114501535892487\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 69.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11600 iterations: 108.6116446574529 mins\n",
      "Train Loss: 0.22717377543449402\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11800 iterations: 110.4187402844429 mins\n",
      "Train Loss: 0.1306021362543106\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 71.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12000 iterations: 112.26359493732453 mins\n",
      "Train Loss: 0.20210424065589905\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12200 iterations: 114.05767027139663 mins\n",
      "Train Loss: 0.16442334651947021\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12400 iterations: 115.85847773949305 mins\n",
      "Train Loss: 0.1381802260875702\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 60.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12600 iterations: 117.69518127441407 mins\n",
      "Train Loss: 0.15804137289524078\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12800 iterations: 119.6547990679741 mins\n",
      "Train Loss: 0.14736588299274445\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13000 iterations: 121.60659616788229 mins\n",
      "Train Loss: 0.12890717387199402\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13200 iterations: 123.4266859372457 mins\n",
      "Train Loss: 0.10635010898113251\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 69.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13400 iterations: 125.24852823813757 mins\n",
      "Train Loss: 0.09538009762763977\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13600 iterations: 127.06594667434692 mins\n",
      "Train Loss: 0.1626003086566925\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 73.2, previous best: 72.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13800 iterations: 128.85703759590785 mins\n",
      "Train Loss: 0.32922011613845825\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 76.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 76.4, previous best: 73.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14000 iterations: 130.61878453095753 mins\n",
      "Train Loss: 0.14361929893493652\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14200 iterations: 132.43965063095092 mins\n",
      "Train Loss: 0.11857756972312927\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 73.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14400 iterations: 134.24698913494746 mins\n",
      "Train Loss: 0.26928141713142395\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14600 iterations: 135.99449942906696 mins\n",
      "Train Loss: 0.14127105474472046\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14800 iterations: 137.7554041147232 mins\n",
      "Train Loss: 0.18216948211193085\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15000 iterations: 139.5817441503207 mins\n",
      "Train Loss: 0.15236537158489227\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 69.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15200 iterations: 141.3795499563217 mins\n",
      "Train Loss: 0.12082542479038239\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15400 iterations: 143.17750194867452 mins\n",
      "Train Loss: 0.14710812270641327\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15600 iterations: 144.99218428929646 mins\n",
      "Train Loss: 0.14013755321502686\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15800 iterations: 146.80469801823298 mins\n",
      "Train Loss: 0.09873728454113007\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 78.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 78.0, previous best: 76.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16000 iterations: 148.6179275949796 mins\n",
      "Train Loss: 0.09564495831727982\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16200 iterations: 150.52573263645172 mins\n",
      "Train Loss: 0.10536576807498932\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 62.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16400 iterations: 152.31893186569215 mins\n",
      "Train Loss: 0.0919925719499588\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 71.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16600 iterations: 154.05943150520324 mins\n",
      "Train Loss: 0.10370822250843048\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16800 iterations: 155.80244121948877 mins\n",
      "Train Loss: 0.0977114662528038\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17000 iterations: 157.55313830773036 mins\n",
      "Train Loss: 0.22102238237857819\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 68.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17200 iterations: 159.30215347210566 mins\n",
      "Train Loss: 0.15409702062606812\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17400 iterations: 161.04410924514136 mins\n",
      "Train Loss: 0.09735654294490814\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17600 iterations: 162.78893480698267 mins\n",
      "Train Loss: 0.10546135157346725\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 63.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17800 iterations: 164.53232517639796 mins\n",
      "Train Loss: 0.09934030473232269\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 70.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18000 iterations: 166.26853353182474 mins\n",
      "Train Loss: 0.1642833650112152\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18200 iterations: 168.00989224910737 mins\n",
      "Train Loss: 0.111887127161026\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 75.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18400 iterations: 169.7664232770602 mins\n",
      "Train Loss: 0.1266547292470932\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18600 iterations: 171.51673587958018 mins\n",
      "Train Loss: 0.1264641135931015\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18800 iterations: 173.36828566789626 mins\n",
      "Train Loss: 0.12368585914373398\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 71.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19000 iterations: 175.19898930390676 mins\n",
      "Train Loss: 0.09808772057294846\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19200 iterations: 177.0667703270912 mins\n",
      "Train Loss: 0.12342989444732666\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19400 iterations: 179.06011888980865 mins\n",
      "Train Loss: 0.11160913854837418\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 72.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19600 iterations: 180.9174479842186 mins\n",
      "Train Loss: 0.09459894150495529\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 76.0% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19800 iterations: 182.70265905857087 mins\n",
      "Train Loss: 0.11691808700561523\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.2% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 20000 iterations: 184.5341803352038 mins\n",
      "Train Loss: 0.09350983798503876\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 74.0% 20 way one-shot learning accuracy \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs,targets) = createPairs(X,y,sizes,batch_size)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model,Xval,yval,sizes_val, N_way, n_val, verbose=True)\n",
    "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted :  0.9939139  actual :  1\n",
      "predicted :  0.0  actual :  0\n",
      "predicted :  0.9986825  actual :  1\n",
      "predicted :  0.0  actual :  0\n",
      "predicted :  0.98474383  actual :  1\n",
      "predicted :  5.662441e-07  actual :  0\n",
      "predicted :  0.98278785  actual :  1\n",
      "predicted :  0.0003476739  actual :  0\n",
      "predicted :  0.997195  actual :  1\n",
      "predicted :  9.948859e-07  actual :  0\n",
      "acc =  1.0\n"
     ]
    }
   ],
   "source": [
    "#random testing (training set)\n",
    "n=10\n",
    "pairs,label=createPairs(X,y,sizes,n)\n",
    "probs = model.predict(pairs)\n",
    "count=0\n",
    "for i in range(n):\n",
    "    print(\"predicted : \",probs[i][0],\" actual : \",label[i])\n",
    "    if label[i]==1:\n",
    "        if probs[i]>0.5:\n",
    "            count+=1\n",
    "    else:\n",
    "        if probs[i]<0.5:\n",
    "            count+=1 \n",
    "        \n",
    "print(\"acc = \",count/n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted :  0.7119514  actual :  1\n",
      "predicted :  0.0001386106  actual :  0\n",
      "predicted :  0.7787981  actual :  1\n",
      "predicted :  0.0  actual :  0\n",
      "predicted :  0.7972748  actual :  1\n",
      "predicted :  0.0070440173  actual :  0\n",
      "predicted :  0.7438587  actual :  1\n",
      "predicted :  0.00013965368  actual :  0\n",
      "predicted :  0.0012342334  actual :  1\n",
      "predicted :  9.23872e-07  actual :  0\n",
      "predicted :  0.7537019  actual :  1\n",
      "predicted :  1.630187e-05  actual :  0\n",
      "predicted :  0.8445027  actual :  1\n",
      "predicted :  0.0039846897  actual :  0\n",
      "predicted :  0.9506608  actual :  1\n",
      "predicted :  4.87864e-05  actual :  0\n",
      "predicted :  0.7971395  actual :  1\n",
      "predicted :  0.020821214  actual :  0\n",
      "predicted :  0.5858815  actual :  1\n",
      "predicted :  0.00061538815  actual :  0\n",
      "acc =  0.95\n"
     ]
    }
   ],
   "source": [
    "#random testing (testing set)\n",
    "n=20\n",
    "pairs,label=createPairs(Xval,yval,sizes_val,n)\n",
    "probs = model.predict(pairs)\n",
    "count=0\n",
    "for i in range(n):\n",
    "    print(\"predicted : \",probs[i][0],\" actual : \",label[i])\n",
    "    if label[i]==1:\n",
    "        if probs[i][0]>0.5:\n",
    "            count+=1\n",
    "    else:\n",
    "        if probs[i][0]<0.5:\n",
    "            count+=1 \n",
    "        \n",
    "print(\"acc = \",count/n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
