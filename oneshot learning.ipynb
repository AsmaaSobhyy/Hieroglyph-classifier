{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "oneshot learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9EUfmmBja-_"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import skimage.io as io\n",
        "import pickle\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXwbeZYYjbAJ"
      },
      "source": [
        "## Loading data\n",
        "a function that loads the images locations and labels.<br>\n",
        "input: the data path.<br>\n",
        "output:<br>\n",
        "&emsp;&emsp;dataHiero -> a dataframe with index= location of images and label= their labels <br>\n",
        "&emsp;&emsp;img_groups -> a dictionary in the shape of { \"label\" : [array of locations of images labeled with this label] }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noWbwGlLjbAY"
      },
      "source": [
        "path=\"../GlyphDataset/Dataset/Manual/Preprocessed/\"\n",
        "\n",
        "def loadData(folderPictures=path):\n",
        "    \n",
        "    folders=next(os.walk(folderPictures))[1]\n",
        "    img_groups = {}\n",
        "    img_list={}\n",
        "\n",
        "    for folder in folders:\n",
        "        for img_file in os.listdir(folderPictures+folder):\n",
        "            name, \n",
        "            label = img_file.strip('.png').split(\"_\")\n",
        "            \n",
        "            \n",
        "            # One image per class\n",
        "\n",
        "            #if label not in img_groups.keys():\n",
        "            #    img_groups[label] = [folder + \"_\" + name]\n",
        "\n",
        "\n",
        "            # Multiple images per class\n",
        "\n",
        "            if label in img_groups.keys():\n",
        "                img_groups[label].append(folder+\"_\"+name)\n",
        "            else:\n",
        "                img_groups[label] = [folder+\"_\"+name]\n",
        "\n",
        "            img_list[folder+\"_\"+name]=[label]\n",
        "\n",
        "\n",
        "    # Remove class with only one hieroglyph\n",
        "\n",
        "\n",
        "    for k,v in list(img_groups.items()):\n",
        "        if len(v)==1: del img_groups[k]\n",
        "\n",
        "    # Extract only N hieroglyph classes randomly\n",
        "\n",
        "    nclass = len(img_groups.keys())\n",
        "\n",
        "    list_of_class = random.sample(list(img_groups.keys()), nclass)\n",
        "#     print(list_of_class)\n",
        "\n",
        "    short_dico = {x: img_groups[x] for x in list_of_class if x in img_groups}\n",
        "\n",
        "    dataHiero=pd.DataFrame.from_dict(img_list,orient='index')\n",
        "    dataHiero.columns = [\"label\"]\n",
        "    dataHiero = dataHiero[dataHiero.label != 'UNKNOWN']\n",
        "\n",
        "    dataHiero = dataHiero.loc[dataHiero['label'].isin(short_dico)]\n",
        "\n",
        "\n",
        "    dataHiero.reset_index(level=0, inplace=True)\n",
        "\n",
        "    return dataHiero,img_groups"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CaZM8DxjbAp"
      },
      "source": [
        "a function that takes the image groups and load those images<br>\n",
        "input: img_proups dictionary<br>\n",
        "output:<br>\n",
        "&emsp;&emsp;X -> np array of the images<br>\n",
        "&emsp;&emsp;y -> np array of labels<br>\n",
        "&emsp;&emsp;glyph_sizes -> a dictionary in the form of {'label' : (starting index, ending index in X and y)}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO2UaDgTjbAu"
      },
      "source": [
        "def read_images(img_groups,path):\n",
        "    X=[]\n",
        "    y=[]\n",
        "    glyph_sizes={}\n",
        "    low=0\n",
        "    for glyph in img_groups:\n",
        "        category_images=[]\n",
        "        high=low\n",
        "        for img_path in img_groups[glyph] :\n",
        "            folder,name = img_path.split('_')\n",
        "            image = io.imread(path+folder+'/'+name+'_'+glyph+'.png')\n",
        "            X.append(image)\n",
        "            y.append(glyph)\n",
        "            high+=1\n",
        "#         X.append(np.array(category_images))\n",
        "        glyph_sizes[glyph]=(low,high-1)\n",
        "        low=high\n",
        "        \n",
        "    return np.array(X),np.array(y).reshape((-1,1)),glyph_sizes\n",
        "            \n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYwf13e4jbA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "40164a56-2bf4-4e9f-9e17-823f4146688c"
      },
      "source": [
        "dataHiero,img_groups=loadData(folderPictures=path)\n",
        "dataHiero.head()\n",
        "# img_groups"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4ff87f925fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataHiero\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderPictures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataHiero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# img_groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-62ed25224a45>\u001b[0m in \u001b[0;36mloadData\u001b[0;34m(folderPictures)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderPictures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfolders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderPictures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j6RWKkrjbA6"
      },
      "source": [
        "X,y,sizes=read_images(img_groups,path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kNTAe8oQjbBG",
        "outputId": "a030e446-b195-4481-b03e-2b201b17045f"
      },
      "source": [
        "type(X)\n",
        "print(y.shape)\n",
        "print(X.shape)\n",
        "sizes['D21'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2921, 1)\n",
            "(2921, 75, 50)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjQdogROjbBI"
      },
      "source": [
        "saving the images into a pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br2-Xm7bjbBb"
      },
      "source": [
        "#train val split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPS8xCJPjbBh"
      },
      "source": [
        "def get_sizes(X,Y):\n",
        "    sizes={}\n",
        "    for i ,(x,y) in enumerate(zip(X,Y)):\n",
        "#         print(i,x,y)\n",
        "        if y[0] in sizes:\n",
        "            sizes[y[0]].append(i)\n",
        "        else:\n",
        "            sizes[y[0]]=[i]\n",
        "    return sizes\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG1c9UUHjbBi"
      },
      "source": [
        "sizes=get_sizes(X_train,y_train)\n",
        "X=X_train\n",
        "y=y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbrU-fAkjbBn"
      },
      "source": [
        "#saving data as pickle\n",
        "with open(\"train.pickle\", \"wb\") as f:\n",
        "    pickle.dump((X,y,sizes),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4szlW2XjbBo"
      },
      "source": [
        "sizes_val=get_sizes(X_test,y_test)\n",
        "Xval=X_test\n",
        "yval=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkrX6IOujbBp"
      },
      "source": [
        "#saving data as pickle\n",
        "with open(\"test.pickle\", \"wb\") as f:\n",
        "    pickle.dump((Xval,yval,sizes_val),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUfovN9vjbBw"
      },
      "source": [
        "# #saving data as pickle\n",
        "# with open(\"test.pickle\", \"wb\") as f:\n",
        "#     pickle.dump((Xval,yval,sizes_val),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtd7kUY6jbBx"
      },
      "source": [
        "## reading the training tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVz6vsHZ4SeJ"
      },
      "source": [
        "#colab\n",
        "data_path= '/content/drive/MyDrive/hiero_cv/'\n",
        "#local\n",
        "# data_path='./'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k19Gi0fR4BU9",
        "outputId": "cdf0dd13-2c96-4c62-abce-bd11e35dd843"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZPC6wKrjbB4"
      },
      "source": [
        "with open(data_path+\"train.pickle\", \"rb\") as f:\n",
        "    (X,y,sizes) = pickle.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOstoN_vjbB7"
      },
      "source": [
        "with open(data_path+\"test.pickle\", \"rb\") as f:\n",
        "    (Xval,yval,sizes_val) = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmdcIQiwpDLV",
        "outputId": "0d44f9a1-1115-4f46-df94-5903a8bde210"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOB0W_VqjbB8"
      },
      "source": [
        "def initialize_weights(shape, name=None):\n",
        "    \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwz8vTAmjbCB"
      },
      "source": [
        "def initialize_bias(shape, name=None):\n",
        "    \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xJN3eoVjbCQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G63fmh8-jbCR"
      },
      "source": [
        "# def get_siamese_model_2(input_shape):\n",
        "#     \"\"\"\n",
        "#         Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "#     \"\"\"\n",
        "    \n",
        "#     # Define the tensors for the two input images\n",
        "#     left_input = Input(input_shape)\n",
        "#     right_input = Input(input_shape)\n",
        "    \n",
        "#     # Convolutional Neural Network\n",
        "#     model = Sequential()\n",
        "#     model.add(Conv2D(64, (3,3),strides=(2, 2), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "#     model.add(MaxPooling2D((2, 2), strides=2))\n",
        "#     model.add(Conv2D(64, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "#     model.add(MaxPooling2D((2, 2), strides=2))\n",
        "#     model.add(Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "# #     model.add(MaxPooling2D())\n",
        "# #     model.add(Conv2D(256, (4,4), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(4096, activation='sigmoid',\n",
        "#                    kernel_regularizer=l2(1e-3)))\n",
        "    \n",
        "#     # Generate the encodings (feature vectors) for the two images\n",
        "#     encoded_l = model(left_input)\n",
        "#     encoded_r = model(right_input)\n",
        "    \n",
        "#     # Add a customized layer to compute the absolute difference between the encodings\n",
        "#     L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "#     L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "#     # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "#     prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
        "    \n",
        "#     # Connect the inputs with the outputs\n",
        "#     siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "#     # return the model\n",
        "#     return siamese_net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pLzzLePsjbCS"
      },
      "source": [
        "# model_2 = get_siamese_model_2((75, 50, 1))\n",
        "# model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk2Tsft9jbCT"
      },
      "source": [
        "# optimizer = Adam(lr = 0.001)\n",
        "# model_2.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFcNXLnxjbCT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodoNhCYjbCU"
      },
      "source": [
        "# def transfer_model(input_shape):\n",
        "#     \"\"\"\n",
        "#         Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "#     \"\"\"\n",
        "    \n",
        "#     # Define the tensors for the two input images\n",
        "#     left_input = Input(input_shape)\n",
        "#     right_input = Input(input_shape)\n",
        "    \n",
        "#     #Import inception model for transfer learning without output layers\n",
        "#     base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = input_shape)\n",
        "    \n",
        "    \n",
        "#     x = base_model.output\n",
        "#     x = GlobalAveragePooling2D()(x)\n",
        "#     # let's add a fully-connected layer\n",
        "#     x = Dense(1024, activation='relu')(x)\n",
        "#     # and a logistic layer -- let's say we have 200 classes\n",
        "#     model= Dense(200, activation='softmax')(x)\n",
        "    \n",
        "#     # this is the model we will train\n",
        "# #     model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        \n",
        "    \n",
        "#     # Generate the encodings (feature vectors) for the two images\n",
        "#     encoded_l = model(left_input)\n",
        "#     encoded_r = model(right_input)\n",
        "    \n",
        "#     # Add a customized layer to compute the absolute difference between the encodings\n",
        "#     L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "#     L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "#     # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "#     prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
        "    \n",
        "#     # Connect the inputs with the outputs\n",
        "#     model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "#     for layer in model.layers[:249]:\n",
        "#        layer.trainable = False\n",
        "#     for layer in model.layers[249:]:\n",
        "#        layer.trainable = True\n",
        "    \n",
        "#     # return the model\n",
        "#     return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-fIRWtajbCV"
      },
      "source": [
        "# inception_model = transfer_model((75, 50, 1))\n",
        "# inception_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEfmyM_KjbCW"
      },
      "source": [
        "# inception_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRlqnliu5So9"
      },
      "source": [
        "from keras import backend as K"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpR7qVOCjbCX"
      },
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    # Convolutional Neural Network\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu',  kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(4096, activation='relu',\n",
        "                   kernel_regularizer=l2(1e-3)))\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    \n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    L1_distance = Dense(512,activation='relu',kernel_regularizer=l2(1e-3))(L1_distance)\n",
        "    L1_distance = Dense(256,activation='relu',kernel_regularizer=l2(1e-3))(L1_distance)\n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "\n",
        "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
        "\n",
        "    #cosine similarity\n",
        "    # def cosine_distance(vests):\n",
        "    #   x, y = vests\n",
        "    #   x = K.l2_normalize(x, axis=-1)\n",
        "    #   y = K.l2_normalize(y, axis=-1)\n",
        "    #   return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "    \n",
        "    \n",
        "    # prediction = Lambda(cosine_distance, output_shape=1)([encoded_l, encoded_r])\n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    # return the model\n",
        "    return siamese_net"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MtvWYCyjbCb",
        "outputId": "8b24e972-165e-4407-a1ba-4ed4d3205270"
      },
      "source": [
        "model = get_siamese_model((75, 50, 1))\n",
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 75, 50, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 75, 50, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 4096)         4891712     input_11[0][0]                   \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 4096)         0           sequential_5[0][0]               \n",
            "                                                                 sequential_5[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 512)          2097664     lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 256)          131328      dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1)            257         dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,120,961\n",
            "Trainable params: 7,120,961\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpDd_9CWjbCd",
        "outputId": "d48dfd96-f534-4ae6-e9a2-a2c72a008163"
      },
      "source": [
        "optimizer = Adam(lr = 0.0001)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNSpnQaljbCe"
      },
      "source": [
        "a function that create pairs of images with y= 1 if they are similar and 0 if they are different. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBHJas8jbCf"
      },
      "source": [
        "## a function to predict which glyph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kua3lTs3jbCf"
      },
      "source": [
        "def create_glyphlist(X,sizes):\n",
        "    images=[]\n",
        "    labels=[]\n",
        "    _,w,h=X.shape\n",
        "    for glyph in sizes:\n",
        "        index=sizes[glyph][0]\n",
        "        images.append(X[index].reshape( w , h, 1))\n",
        "        labels.append(glyph)\n",
        "    return np.asarray(images), np.asarray(labels) "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTWwXWyBjbCn"
      },
      "source": [
        "anchor_img, anchor_label=create_glyphlist(X,sizes)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV5F8TRwjbCo"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj5krLHkjbCo"
      },
      "source": [
        "def whichGlyph_pair(image,anchor_img,anchor_label):\n",
        "    N,w,h,_=anchor_img.shape\n",
        "#     pairs=[np.zeros((N, w, h,1)) for i in range(2)]\n",
        "    \n",
        "    test_image= np.asarray([image]*N).reshape(N, w, h,1)\n",
        "    \n",
        "    anchor_label, test_image, anchor_img = shuffle(anchor_label, test_image, anchor_img)\n",
        "#     pairs = [test_image,anchor_img]\n",
        "    \n",
        "    return test_image, anchor_img, anchor_label\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzVYcJ4tjbCp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrc8caDFjbCp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6a5mx_MjbCq"
      },
      "source": [
        "def whichGlyph(model,image,anchor_img,anchor_label):\n",
        "    test_image,anchor_img,targets = whichGlyph_pair(image,anchor_img,anchor_label)\n",
        "    probs = model.predict([test_image,anchor_img])\n",
        "    return probs,anchor_img,targets\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUxUIQb8jbC1"
      },
      "source": [
        "# def whichGlyph(model,image,anchor_img,anchor_label):\n",
        "#     test_image,anchor_img,targets = whichGlyph_pair(image,anchor_img,anchor_label)\n",
        "#     probs=[]\n",
        "#     for i in range(0,len(targets),2):\n",
        "#         pair=[[test_image[i],test_image[i+1]],[anchor_img[i],anchor_img[i+1]]]\n",
        "#         pred=model.predict(pair)\n",
        "#         for p in pred:\n",
        "#             probs.append(p)\n",
        "        \n",
        "#     return probs,anchor_img,targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb2Uo1PrjbC2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arWKCACTjbC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2SsLM6ujbC5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM5fQribjbC5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xCa5bCWjbC6"
      },
      "source": [
        "## creating pairs of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7t5J2GCjbC7"
      },
      "source": [
        "def createPairs(X,y,sizes,batch_size):\n",
        "    ##create a batch with half it's size are similar glyphs and the other half are different.\n",
        "    n=0\n",
        "    i=0\n",
        "    \n",
        "    label=[]\n",
        "    _,w,h=X.shape\n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "#     pairs=[np.zeros((batch_size, w, h,1)) for i in range(2)]\n",
        "    input1=np.zeros((batch_size, w, h,1))\n",
        "    input2=np.zeros((batch_size, w, h,1))\n",
        "    \n",
        "    while n < batch_size:\n",
        "        random_key1=random.choice(list(sizes))\n",
        "#         low=sizes[random_key1][0]\n",
        "#         high=sizes[random_key1][1]\n",
        "        index1, index3 = np.random.choice(sizes[random_key1], size=2)\n",
        "        index2 = np.random.choice(sizes[random_key1])\n",
        "        random_key2=random.choice(list(sizes))\n",
        "        \n",
        "        while random_key2 == random_key1:\n",
        "            random_key2=random.choice(list(sizes))\n",
        "            \n",
        "#         low=sizes[random_key2][0]\n",
        "#         high=sizes[random_key2][1]\n",
        "        index4=np.random.choice(sizes[random_key2])\n",
        "        n += 2\n",
        "        # appending images 1 and 3 into input1 and input2 corresponding to y=1 \n",
        "        #and images 2 and 4 corresponding to y=0\n",
        "    \n",
        "        input1[i,:,:,:] = X[index1].reshape( w , h, 1)\n",
        "        input1[i+1,:,:,:] = X[index2].reshape(w, h, 1)\n",
        "        input2[i,:,:,:] = X[index3].reshape(w, h, 1)\n",
        "        input2[i+1,:,:,:] = X[index4].reshape(w, h, 1)\n",
        "        i += 2\n",
        "#         input1+=[X[index1],X[index2]]\n",
        "#         input2+=[X[index3],X[index4]]\n",
        "        label+=[1,0]\n",
        "        \n",
        "#         print(index1,index2,index3,index4)\n",
        "#         print(y[index1],y[index2],y[index3],y[index4])\n",
        "#         print(random_key1,random_key2)\n",
        "    input1,input2,label = shuffle(input1,input2,label)\n",
        "    pairs=[input1,input2]\n",
        "    \n",
        "    return pairs,label\n",
        "pairs,label=createPairs(X,y,sizes,32)   "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXoehBUTjbC9"
      },
      "source": [
        "# pairs[1].shape\n",
        "# label"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alqGHaxLjbC-"
      },
      "source": [
        "a fn that creates a N-way one shot learning task where it create pairs with the wanted image and N-1 different ones and 1 similar one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVWV2CnbjbC-"
      },
      "source": [
        "def make_oneshot_task(X,y,sizes,N):\n",
        "    _,w,h=X.shape\n",
        "    pairs=[np.zeros((N, w, h,1)) for i in range(2)]\n",
        "    \n",
        "    true_key=random.choice(list(sizes))\n",
        "#     low=sizes[true_key][0]\n",
        "#     high=sizes[true_key][1]\n",
        "    \n",
        "    index=np.random.choice(sizes[true_key])\n",
        "    index2=np.random.choice(sizes[true_key])\n",
        "    \n",
        "    test_image= np.asarray([X[index]]*N).reshape(N, w, h,1)\n",
        "#     print(X.shape)\n",
        "    X_diff= np.delete(X,sizes[true_key],axis=0)\n",
        "#     print(X_diff.shape)\n",
        "    indices= np.random.choice(range(0, len(X_diff)), size = N-1)\n",
        "    \n",
        "    support_set=X_diff[indices,:,:]\n",
        "    ##!!! adding the similar image to the start of the array is not working!!!!!!!!!!!!!!!!!!!!!\n",
        "    \n",
        "#     print(support_set.shape)\n",
        "#     support_set = [ X[index2] ] + support_set\n",
        "    support_set=np.insert(support_set,0,X[index2],axis=0)\n",
        "#     print(support_set.shape)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    support_set=support_set.reshape(N,w,h,1)\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image,support_set]\n",
        "\n",
        "    return pairs, targets\n",
        "    \n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27BD6Rg9jbDO",
        "outputId": "b07478be-0ea4-401c-c5cc-6f0117d0a430"
      },
      "source": [
        "pp,tt=make_oneshot_task(Xval,yval,sizes_val,20) \n",
        "pp[0].shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 75, 50, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6lenk9bjbDP",
        "outputId": "ef83aa0b-10f5-47da-e0cf-51048b493898"
      },
      "source": [
        "# plt.imshow(pairs[0][0])\n",
        "pairs[1].shape\n",
        "# len(label)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 75, 50, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr6bSOuBjbDZ"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8POHa_JjbDZ"
      },
      "source": [
        "def test_oneshot(model,X,y,sizes, N, k, s = \"val\", verbose = 0):\n",
        "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(X,y,sizes,N)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct+=1\n",
        "    percent_correct = (100.0 * n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
        "    return percent_correct"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbUqy4FNjbDf"
      },
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
        "batch_size = 128 #32\n",
        "n_iter = 20000 # No. of training iterations 20000\n",
        "N_way = 20 # how many classes for testing one-shot tasks\n",
        "n_val = 250 # how many one-shot tasks to validate on\n",
        "best = -1"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJXH6WomjbDg"
      },
      "source": [
        "model_path = './weights/'\n",
        "model_2_path= '/content/drive/MyDrive/hiero_cv/weights/'\n",
        "model_cos_path= '/content/drive/MyDrive/hiero_cv/weights_cos/'\n",
        "model_regul='/content/drive/MyDrive/hiero_cv/regul_weights/'"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUJcfqJLjbDh",
        "outputId": "f9789a60-ba83-47b0-b60b-08942bf2689c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2921, 75, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwLw68YljbDj",
        "outputId": "573b6029-8592-449a-cfca-2b743a97631d"
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs,targets) = createPairs(X,y,sizes,batch_size)\n",
        "    targets=np.asarray(targets)\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        val_acc = test_oneshot(model,Xval,yval,sizes_val, N_way, n_val, verbose=True)\n",
        "        model.save_weights(os.path.join(model_regul, 'weights.{}.h5'.format(i)))\n",
        "        if val_acc >= best:\n",
        "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
        "            best = val_acc"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training process!\n",
            "-------------------------------------\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 200 iterations: 0.1632342219352722 mins\n",
            "Train Loss: 1.757617473602295\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 34.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 400 iterations: 0.6109503189722697 mins\n",
            "Train Loss: 1.326379656791687\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 57.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 600 iterations: 1.0458414435386658 mins\n",
            "Train Loss: 1.2002668380737305\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 48.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 800 iterations: 1.506370194753011 mins\n",
            "Train Loss: 1.0505802631378174\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1000 iterations: 1.9418940742810566 mins\n",
            "Train Loss: 0.9934638142585754\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1200 iterations: 2.4009190956751505 mins\n",
            "Train Loss: 0.9247583746910095\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1400 iterations: 2.848350199063619 mins\n",
            "Train Loss: 0.8151292204856873\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1600 iterations: 3.30295379559199 mins\n",
            "Train Loss: 0.6825851202011108\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1800 iterations: 3.7353340943654376 mins\n",
            "Train Loss: 0.694847583770752\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2000 iterations: 4.176967950661977 mins\n",
            "Train Loss: 0.5613130331039429\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2200 iterations: 4.6063040614128115 mins\n",
            "Train Loss: 0.5745661854743958\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2400 iterations: 5.054045255978902 mins\n",
            "Train Loss: 0.6127685308456421\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2600 iterations: 5.480607199668884 mins\n",
            "Train Loss: 0.44940727949142456\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2800 iterations: 5.921436750888825 mins\n",
            "Train Loss: 0.5314142107963562\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3000 iterations: 6.346219344933828 mins\n",
            "Train Loss: 0.4107707440853119\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3200 iterations: 6.785185956954956 mins\n",
            "Train Loss: 0.4026004374027252\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3400 iterations: 7.214966030915578 mins\n",
            "Train Loss: 0.47024041414260864\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3600 iterations: 7.652374720573425 mins\n",
            "Train Loss: 0.6655032634735107\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3800 iterations: 8.087332014242808 mins\n",
            "Train Loss: 0.31044262647628784\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4000 iterations: 8.527723371982574 mins\n",
            "Train Loss: 0.27295738458633423\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4200 iterations: 8.960495046774547 mins\n",
            "Train Loss: 0.252652645111084\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4400 iterations: 9.400358339150747 mins\n",
            "Train Loss: 0.4005489945411682\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4600 iterations: 9.835023840268454 mins\n",
            "Train Loss: 0.24594536423683167\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4800 iterations: 10.277496389547984 mins\n",
            "Train Loss: 0.22878144681453705\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5000 iterations: 10.70778869787852 mins\n",
            "Train Loss: 0.2203093022108078\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5200 iterations: 11.149654805660248 mins\n",
            "Train Loss: 0.2875341773033142\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5400 iterations: 11.577025008201598 mins\n",
            "Train Loss: 0.19362644851207733\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5600 iterations: 12.01591742436091 mins\n",
            "Train Loss: 0.22339802980422974\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5800 iterations: 12.445531006654104 mins\n",
            "Train Loss: 0.15968909859657288\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6000 iterations: 12.88999860684077 mins\n",
            "Train Loss: 0.16142648458480835\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6200 iterations: 13.336358348528544 mins\n",
            "Train Loss: 0.1727634072303772\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6400 iterations: 13.795092829068501 mins\n",
            "Train Loss: 0.1991325467824936\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6600 iterations: 14.241026469071706 mins\n",
            "Train Loss: 0.13496257364749908\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6800 iterations: 14.699463093280793 mins\n",
            "Train Loss: 0.33642032742500305\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7000 iterations: 15.142706374327341 mins\n",
            "Train Loss: 0.12952597439289093\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7200 iterations: 15.596030080318451 mins\n",
            "Train Loss: 0.14995500445365906\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7400 iterations: 16.046047202746074 mins\n",
            "Train Loss: 0.1389111429452896\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7600 iterations: 16.507032946745554 mins\n",
            "Train Loss: 0.19003017246723175\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7800 iterations: 16.96297177473704 mins\n",
            "Train Loss: 0.17651094496250153\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8000 iterations: 17.42383237282435 mins\n",
            "Train Loss: 0.15469497442245483\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8200 iterations: 17.874660034974415 mins\n",
            "Train Loss: 0.2799180746078491\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8400 iterations: 18.341619996229806 mins\n",
            "Train Loss: 0.09941888600587845\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8600 iterations: 18.800783598423003 mins\n",
            "Train Loss: 0.0922480970621109\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8800 iterations: 19.262899907430015 mins\n",
            "Train Loss: 0.11810512840747833\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9000 iterations: 19.721179656187694 mins\n",
            "Train Loss: 0.10093643516302109\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9200 iterations: 20.191370383898416 mins\n",
            "Train Loss: 0.08547918498516083\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9400 iterations: 20.65096991856893 mins\n",
            "Train Loss: 0.10217178612947464\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9600 iterations: 21.11627592643102 mins\n",
            "Train Loss: 0.08332475274801254\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9800 iterations: 21.56900281906128 mins\n",
            "Train Loss: 0.08301812410354614\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10000 iterations: 22.033463195959726 mins\n",
            "Train Loss: 0.07901385426521301\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10200 iterations: 22.483168462912243 mins\n",
            "Train Loss: 0.07650099694728851\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10400 iterations: 22.943891672293343 mins\n",
            "Train Loss: 0.07607118785381317\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10600 iterations: 23.398249169190724 mins\n",
            "Train Loss: 0.08776901662349701\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10800 iterations: 23.863017268975575 mins\n",
            "Train Loss: 0.07495000213384628\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11000 iterations: 24.313438113530477 mins\n",
            "Train Loss: 0.08922476321458817\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11200 iterations: 24.779689606030782 mins\n",
            "Train Loss: 0.077898770570755\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11400 iterations: 25.242208210627236 mins\n",
            "Train Loss: 0.2027658224105835\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11600 iterations: 25.715813048680623 mins\n",
            "Train Loss: 0.07341407239437103\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11800 iterations: 26.17433854738871 mins\n",
            "Train Loss: 0.06609585136175156\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12000 iterations: 26.642353467146556 mins\n",
            "Train Loss: 0.10545159131288528\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12200 iterations: 27.10125019152959 mins\n",
            "Train Loss: 0.0636761337518692\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12400 iterations: 27.571155345439912 mins\n",
            "Train Loss: 0.06940262764692307\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12600 iterations: 28.023714383443195 mins\n",
            "Train Loss: 0.06242029741406441\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12800 iterations: 28.491730093955994 mins\n",
            "Train Loss: 0.07014517486095428\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13000 iterations: 28.946151276429493 mins\n",
            "Train Loss: 0.07388821244239807\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13200 iterations: 29.41470795472463 mins\n",
            "Train Loss: 0.07406729459762573\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13400 iterations: 29.87714041074117 mins\n",
            "Train Loss: 0.0633968934416771\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13600 iterations: 30.349276045958202 mins\n",
            "Train Loss: 0.07783818244934082\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13800 iterations: 30.807161287466684 mins\n",
            "Train Loss: 0.09088514745235443\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14000 iterations: 31.27766322294871 mins\n",
            "Train Loss: 0.05831527337431908\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14200 iterations: 31.73156503836314 mins\n",
            "Train Loss: 0.15702252089977264\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14400 iterations: 32.19751983086268 mins\n",
            "Train Loss: 0.05182662606239319\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14600 iterations: 32.65693480571111 mins\n",
            "Train Loss: 0.053049229085445404\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14800 iterations: 33.12437982956568 mins\n",
            "Train Loss: 0.05367755517363548\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15000 iterations: 33.57403531869252 mins\n",
            "Train Loss: 0.20057842135429382\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15200 iterations: 34.04283803701401 mins\n",
            "Train Loss: 0.05278400704264641\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15400 iterations: 34.501684137185414 mins\n",
            "Train Loss: 0.05149546638131142\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15600 iterations: 34.97431265910466 mins\n",
            "Train Loss: 0.049982424825429916\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15800 iterations: 35.42719583908717 mins\n",
            "Train Loss: 0.06344904750585556\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16000 iterations: 35.89651244481404 mins\n",
            "Train Loss: 0.0643712729215622\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16200 iterations: 36.33897922039032 mins\n",
            "Train Loss: 0.0666060596704483\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16400 iterations: 36.792595001061756 mins\n",
            "Train Loss: 0.04863642901182175\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16600 iterations: 37.22860721349716 mins\n",
            "Train Loss: 0.15309152007102966\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16800 iterations: 37.68476240237554 mins\n",
            "Train Loss: 0.05265646427869797\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17000 iterations: 38.11507524649302 mins\n",
            "Train Loss: 0.04572995752096176\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17200 iterations: 38.57710327704748 mins\n",
            "Train Loss: 0.05023398995399475\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17400 iterations: 39.01859715779622 mins\n",
            "Train Loss: 0.045705705881118774\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17600 iterations: 39.48387757142385 mins\n",
            "Train Loss: 0.045630525797605515\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17800 iterations: 39.9280481616656 mins\n",
            "Train Loss: 0.05151836946606636\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18000 iterations: 40.39056814114253 mins\n",
            "Train Loss: 0.044775430113077164\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18200 iterations: 40.84437400897344 mins\n",
            "Train Loss: 0.043029408901929855\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18400 iterations: 41.31618129809697 mins\n",
            "Train Loss: 0.042767029255628586\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18600 iterations: 41.76450822750727 mins\n",
            "Train Loss: 0.05061161890625954\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18800 iterations: 42.23480994701386 mins\n",
            "Train Loss: 0.08832649141550064\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19000 iterations: 42.68395086129507 mins\n",
            "Train Loss: 0.042940057814121246\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19200 iterations: 43.150698939959206 mins\n",
            "Train Loss: 0.04257776960730553\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19400 iterations: 43.60516211191813 mins\n",
            "Train Loss: 0.04358070343732834\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19600 iterations: 44.08009024461111 mins\n",
            "Train Loss: 0.04610199108719826\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19800 iterations: 44.52360705534617 mins\n",
            "Train Loss: 0.041835080832242966\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 20000 iterations: 44.991921778519945 mins\n",
            "Train Loss: 0.060331299901008606\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4JoCm_5jbDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630d026e-7dd4-4310-e8d5-e7cb68e9cc03"
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs,targets) = createPairs(X,y,sizes,batch_size)\n",
        "    targets=np.asarray(targets)\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        val_acc = test_oneshot(model,Xval,yval,sizes_val, N_way, n_val, verbose=True)\n",
        "        model.save_weights(os.path.join(model_cos_path, 'weights.{}.h5'.format(i)))\n",
        "        if val_acc >= best:\n",
        "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
        "            best = val_acc"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training process!\n",
            "-------------------------------------\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 200 iterations: 0.1746594190597534 mins\n",
            "Train Loss: 1.099053978919983\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 32.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 32.0, previous best: 5.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 400 iterations: 0.643968419233958 mins\n",
            "Train Loss: 0.7923591136932373\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 44.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 44.4, previous best: 32.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 600 iterations: 1.0733067393302917 mins\n",
            "Train Loss: 0.6323250532150269\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 42.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 800 iterations: 1.5318235596021017 mins\n",
            "Train Loss: 0.5148969888687134\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 50.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 50.8, previous best: 44.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1000 iterations: 1.966246787707011 mins\n",
            "Train Loss: 0.4932793974876404\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 56.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 56.8, previous best: 50.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1200 iterations: 2.4189886411031085 mins\n",
            "Train Loss: 0.41171497106552124\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 65.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 65.6, previous best: 56.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1400 iterations: 2.8509631951649985 mins\n",
            "Train Loss: 0.5204046964645386\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 59.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1600 iterations: 3.307607913017273 mins\n",
            "Train Loss: 0.4015348553657532\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 79.2, previous best: 65.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1800 iterations: 3.7368996143341064 mins\n",
            "Train Loss: 0.33342134952545166\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2000 iterations: 4.186650820573171 mins\n",
            "Train Loss: 0.27928614616394043\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2200 iterations: 4.616149091720581 mins\n",
            "Train Loss: 0.24110417068004608\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2400 iterations: 5.0671799341837565 mins\n",
            "Train Loss: 0.30818530917167664\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2600 iterations: 5.500994006792705 mins\n",
            "Train Loss: 0.25923705101013184\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 82.0, previous best: 79.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2800 iterations: 5.958911406993866 mins\n",
            "Train Loss: 0.21257364749908447\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3000 iterations: 6.392449295520782 mins\n",
            "Train Loss: 0.24526262283325195\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3200 iterations: 6.8444047729174295 mins\n",
            "Train Loss: 0.3597479462623596\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3400 iterations: 7.283158850669861 mins\n",
            "Train Loss: 0.2343580722808838\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 84.8, previous best: 82.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3600 iterations: 7.734531438350677 mins\n",
            "Train Loss: 0.17998848855495453\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3800 iterations: 8.172745231787363 mins\n",
            "Train Loss: 0.2834080159664154\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 84.8, previous best: 84.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4000 iterations: 8.62520763874054 mins\n",
            "Train Loss: 0.2758420705795288\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4200 iterations: 9.068666295210521 mins\n",
            "Train Loss: 0.17613059282302856\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 85.6, previous best: 84.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4400 iterations: 9.52633341550827 mins\n",
            "Train Loss: 0.20929768681526184\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 86.8, previous best: 85.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4600 iterations: 9.973100113868714 mins\n",
            "Train Loss: 0.15058918297290802\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4800 iterations: 10.421363723278045 mins\n",
            "Train Loss: 0.20774292945861816\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 87.6, previous best: 86.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5000 iterations: 10.858312904834747 mins\n",
            "Train Loss: 0.20485100150108337\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5200 iterations: 11.30764109690984 mins\n",
            "Train Loss: 0.21643328666687012\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 87.6, previous best: 87.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5400 iterations: 11.746405522028605 mins\n",
            "Train Loss: 0.11923318356275558\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5600 iterations: 12.195228083928425 mins\n",
            "Train Loss: 0.11784292757511139\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5800 iterations: 12.634225408236185 mins\n",
            "Train Loss: 0.11309368908405304\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6000 iterations: 13.087394376595816 mins\n",
            "Train Loss: 0.1895127296447754\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6200 iterations: 13.523718357086182 mins\n",
            "Train Loss: 0.15093296766281128\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 90.0, previous best: 87.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6400 iterations: 13.973644419511158 mins\n",
            "Train Loss: 0.10634342581033707\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6600 iterations: 14.410167586803436 mins\n",
            "Train Loss: 0.09645229578018188\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 90.4, previous best: 90.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6800 iterations: 14.85768030087153 mins\n",
            "Train Loss: 0.09865891933441162\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 91.6, previous best: 90.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7000 iterations: 15.293667840957642 mins\n",
            "Train Loss: 0.10510322451591492\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7200 iterations: 15.748277533054353 mins\n",
            "Train Loss: 0.09242498874664307\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7400 iterations: 16.18186445236206 mins\n",
            "Train Loss: 0.13275405764579773\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7600 iterations: 16.63546304702759 mins\n",
            "Train Loss: 0.08627462387084961\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7800 iterations: 17.06758604447047 mins\n",
            "Train Loss: 0.18016386032104492\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8000 iterations: 17.523516643047333 mins\n",
            "Train Loss: 0.33448415994644165\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8200 iterations: 17.96790484984716 mins\n",
            "Train Loss: 0.21045321226119995\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8400 iterations: 18.426459741592407 mins\n",
            "Train Loss: 0.27891379594802856\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8600 iterations: 18.868672899405162 mins\n",
            "Train Loss: 0.08785413950681686\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8800 iterations: 19.327458918094635 mins\n",
            "Train Loss: 0.07562282681465149\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9000 iterations: 19.75818886756897 mins\n",
            "Train Loss: 0.08521339297294617\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9200 iterations: 20.207601435979207 mins\n",
            "Train Loss: 0.08059345185756683\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9400 iterations: 20.642009635766346 mins\n",
            "Train Loss: 0.08334529399871826\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9600 iterations: 21.101701617240906 mins\n",
            "Train Loss: 0.08148141205310822\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9800 iterations: 21.541348123550414 mins\n",
            "Train Loss: 0.06975436210632324\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10000 iterations: 21.99855525890986 mins\n",
            "Train Loss: 0.07574895024299622\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 92.8, previous best: 91.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10200 iterations: 22.433670337994894 mins\n",
            "Train Loss: 0.07996026426553726\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10400 iterations: 22.889137558142345 mins\n",
            "Train Loss: 0.2020760178565979\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10600 iterations: 23.326107434431712 mins\n",
            "Train Loss: 0.08471935987472534\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10800 iterations: 23.784267342090608 mins\n",
            "Train Loss: 0.06337989866733551\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11000 iterations: 24.222787523269652 mins\n",
            "Train Loss: 0.0836862325668335\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 94.4, previous best: 92.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11200 iterations: 24.677334952354432 mins\n",
            "Train Loss: 0.23277388513088226\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11400 iterations: 25.120954068501792 mins\n",
            "Train Loss: 0.14467717707157135\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11600 iterations: 25.572389713923137 mins\n",
            "Train Loss: 0.0611049048602581\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11800 iterations: 26.010975710550944 mins\n",
            "Train Loss: 0.0673385038971901\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12000 iterations: 26.461334311962126 mins\n",
            "Train Loss: 0.08342976868152618\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12200 iterations: 26.89828411738078 mins\n",
            "Train Loss: 0.06684495508670807\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12400 iterations: 27.349605182806652 mins\n",
            "Train Loss: 0.06394453346729279\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12600 iterations: 27.78601746161779 mins\n",
            "Train Loss: 0.10656052827835083\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12800 iterations: 28.236573080221813 mins\n",
            "Train Loss: 0.07270816713571548\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13000 iterations: 28.679081253210704 mins\n",
            "Train Loss: 0.10347452759742737\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13200 iterations: 29.12898324330648 mins\n",
            "Train Loss: 0.12421762198209763\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13400 iterations: 29.56673533519109 mins\n",
            "Train Loss: 0.05893758684396744\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13600 iterations: 30.016030434767405 mins\n",
            "Train Loss: 0.05668092519044876\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13800 iterations: 30.471254968643187 mins\n",
            "Train Loss: 0.0590299591422081\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14000 iterations: 30.936687342325847 mins\n",
            "Train Loss: 0.054167989641427994\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14200 iterations: 31.377377466360727 mins\n",
            "Train Loss: 0.05277037248015404\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14400 iterations: 31.83199320236842 mins\n",
            "Train Loss: 0.1381649374961853\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14600 iterations: 32.262255346775056 mins\n",
            "Train Loss: 0.05275460705161095\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 94.4, previous best: 94.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14800 iterations: 32.716078253587085 mins\n",
            "Train Loss: 0.05410751700401306\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15000 iterations: 33.145687305927275 mins\n",
            "Train Loss: 0.050888169556856155\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15200 iterations: 33.60156026681264 mins\n",
            "Train Loss: 0.11807184666395187\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15400 iterations: 34.04325583775838 mins\n",
            "Train Loss: 0.05108882486820221\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15600 iterations: 34.51044586102168 mins\n",
            "Train Loss: 0.058369193226099014\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15800 iterations: 34.945864482720694 mins\n",
            "Train Loss: 0.048506248742341995\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16000 iterations: 35.40264925956726 mins\n",
            "Train Loss: 0.05213157832622528\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 93.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16200 iterations: 35.84075493415197 mins\n",
            "Train Loss: 0.05249248817563057\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16400 iterations: 36.3015625278155 mins\n",
            "Train Loss: 0.049784623086452484\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 95.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 95.6, previous best: 94.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16600 iterations: 36.7371985634168 mins\n",
            "Train Loss: 0.07430020719766617\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 95.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 95.6, previous best: 95.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16800 iterations: 37.19363648096721 mins\n",
            "Train Loss: 0.06383240967988968\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17000 iterations: 37.63110029697418 mins\n",
            "Train Loss: 0.0479348748922348\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17200 iterations: 38.08209822972616 mins\n",
            "Train Loss: 0.04714309796690941\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17400 iterations: 38.51546502113342 mins\n",
            "Train Loss: 0.06913779675960541\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17600 iterations: 38.966032127539314 mins\n",
            "Train Loss: 0.045809775590896606\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 89.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17800 iterations: 39.40655783812205 mins\n",
            "Train Loss: 0.08614779263734818\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18000 iterations: 39.86267168919245 mins\n",
            "Train Loss: 0.04605609551072121\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18200 iterations: 40.30662132104238 mins\n",
            "Train Loss: 0.04606236517429352\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18400 iterations: 40.756139957904814 mins\n",
            "Train Loss: 0.08583875000476837\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18600 iterations: 41.190426127115884 mins\n",
            "Train Loss: 0.05568676069378853\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18800 iterations: 41.629124609629315 mins\n",
            "Train Loss: 0.04414251446723938\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19000 iterations: 42.06066465775172 mins\n",
            "Train Loss: 0.04618705064058304\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19200 iterations: 42.50009829203288 mins\n",
            "Train Loss: 0.04987756535410881\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19400 iterations: 42.93675682942072 mins\n",
            "Train Loss: 0.044829171150922775\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 91.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19600 iterations: 43.39305727481842 mins\n",
            "Train Loss: 0.06317868828773499\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19800 iterations: 43.8301841934522 mins\n",
            "Train Loss: 0.06860257685184479\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 95.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 20000 iterations: 44.27989245653153 mins\n",
            "Train Loss: 0.04542369395494461\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 88.0% 20 way one-shot learning accuracy \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcTZ3HHJjbDp"
      },
      "source": [
        "## loading model from weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt8pqshBxKcQ"
      },
      "source": [
        "# model_path="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XSzGDRhjbDr"
      },
      "source": [
        "model.load_weights(model_cos_path+'weights.20000.h5')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFJVIYiajbDs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDQXUEmFjbDt"
      },
      "source": [
        "def calc_accuracy(N,Xval,yval,anchor_img,anchor_label,model):\n",
        "    count_first=0\n",
        "    count_first3=0\n",
        "    for i in range(N):\n",
        "        ind=random.choice(range(yval.shape[0]))\n",
        "        predicted,anchor_imgs,targets=whichGlyph(model,Xval[ind],anchor_img,anchor_label)\n",
        "        sort_index = np.argsort(np.asarray(predicted).reshape(len(predicted),))\n",
        "        if targets[sort_index[-1]] == yval[ind][0]:\n",
        "            count_first+=1\n",
        "        if yval[ind][0] in targets[sort_index[127:]]:\n",
        "            count_first3+=1\n",
        "    accuracy_first=count_first/N\n",
        "    accuracy_first3=count_first3/N\n",
        "    \n",
        "    return accuracy_first, accuracy_first3"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmLQ6lVYjbDt",
        "outputId": "f27811d6-22ea-4555-eff1-482b7afe6110"
      },
      "source": [
        "t_start = time.time()\n",
        "acc1,acc3=calc_accuracy(1000,Xval,yval,anchor_img,anchor_label,model)\n",
        "print(f'testing:\\nfound first accuracy = {acc1} , first 3 accuracy = {acc3}')\n",
        "print(\"accuracy fn took {0} mins\".format((time.time()-t_start)/60.0))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing:\n",
            "found first accuracy = 0.739 , first 3 accuracy = 0.953\n",
            "accuracy fn took 1.8880924224853515 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdtRB3qAjbDw",
        "outputId": "0a976f79-fc1a-41d8-88c2-bc4257ae1fad"
      },
      "source": [
        "t_start = time.time()\n",
        "acc1,acc3=calc_accuracy(250,X,y,anchor_img,anchor_label,model)\n",
        "print(f'training:\\nfound first accuracy = {acc1} , first 3 accuracy = {acc3} ')\n",
        "print(\"accuracy fn took {0} mins\".format((time.time()-t_start)/60.0))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training:\n",
            "found first accuracy = 0.852 , first 3 accuracy = 0.984 \n",
            "accuracy fn took 0.4673379858334859 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poAicP_njbDx"
      },
      "source": [
        "# t_start = time.time()\n",
        "# print(calc_accuracy(1,Xval,yval,anchor_img,anchor_label,model))\n",
        "# print(\"accuracy fn took {0} sec\".format((time.time()-t_start)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beW1a29IjbDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrLEK0fejbDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZplSFXGjbD3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}