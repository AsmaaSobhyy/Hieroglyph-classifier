{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuhHdC1Ai3Ap"
      },
      "source": [
        "NUM_CLASSES = 169\n",
        "\n",
        "CHANNELS = 1\n",
        "img_width, img_height = 75, 70\n",
        "\n",
        "IMAGE_RESIZE = 224\n",
        "RESNET50_POOLING_AVERAGE = 'avg'\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
        "\n",
        "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
        "LOSS_METRICS = ['accuracy']\n",
        "\n",
        "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
        "NUM_EPOCHS = 10\n",
        "EARLY_STOP_PATIENCE = 3\n",
        "\n",
        "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
        "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
        "STEPS_PER_EPOCH_TRAINING = 10\n",
        "STEPS_PER_EPOCH_VALIDATION = 10\n",
        "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
        "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
        "BATCH_SIZE_TRAINING = 32\n",
        "BATCH_SIZE_VALIDATION = 32\n",
        "\n",
        "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
        "BATCH_SIZE_TESTING = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JlpunNLjEtq"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import mobilenet\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_gjTPRxjFk8",
        "outputId": "e36a6fcd-4247-4662-fc4b-fe78cb640faf"
      },
      "source": [
        " \n",
        "model_resnet = ResNet50(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(img_width,img_height,3))\n",
        "model_resnet.layers[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.activation.Activation at 0x7fd624422610>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTzSOaXJoIHn"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "for layer in model_resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# We will have to use the functional API    \n",
        "\n",
        "# last layers output\n",
        "x = model_resnet.layers[-1].output\n",
        "# Flatten as before\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "model = Model(inputs=model_resnet.input, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud12t-FClTqr",
        "outputId": "0e3e0920-96a3-4a3d-e725-06b9d0cbddae"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "sgd = optimizers.SGD(lr = 0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
        "# sgd = optimizers.Adam(lr = 0.01)\n",
        "\n",
        "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsJ5qNkAlpJj",
        "outputId": "1e5c79c2-3517-4957-fe37-b0904bc8eae2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMCAB60pkx0N"
      },
      "source": [
        "# model=Sequential()\n",
        "# #Still not talking about our train/test data or any pre-processing.\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "# # NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
        "# model.add(model_resnet)\n",
        "\n",
        "# # 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
        "# model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
        "\n",
        "# # Say not to train first layer (ResNet) model as it is already trained\n",
        "# model.layers[0].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFcdSwETka_J",
        "outputId": "fac1a06f-f735-41b1-b807-7594de17f5c3"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Batch Normalization helps in faster convergence\n",
        "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "\n",
        "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
        "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dataset/train', \n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=BATCH_SIZE_TRAINING,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dataset/test', \n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=BATCH_SIZE_VALIDATION,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8262 images belonging to 169 classes.\n",
            "Found 1291 images belonging to 169 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8E1nOz8nAoM",
        "outputId": "5917b11d-2ab9-4662-dc1a-bb2b9a7db1a3"
      },
      "source": [
        "# Max number of steps that these generator will have opportunity to process their source content\n",
        "# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n",
        "# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n",
        "(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 259, 32, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qixNFzIlnENy"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mz6tH9fnMww",
        "cellView": "code",
        "outputId": "463d988f-4381-4cfd-b6eb-182f84cc9b43"
      },
      "source": [
        "fit_history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=10,\n",
        "        epochs = 25,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=10,\n",
        "        # callbacks=[cb_early_stopper]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.7029 - accuracy: 0.8095 - val_loss: 1.6506 - val_accuracy: 0.6562\n",
            "Epoch 2/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6948 - accuracy: 0.8250 - val_loss: 1.6409 - val_accuracy: 0.6344\n",
            "Epoch 3/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6204 - accuracy: 0.8406 - val_loss: 1.7678 - val_accuracy: 0.6281\n",
            "Epoch 4/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6688 - accuracy: 0.8375 - val_loss: 1.6743 - val_accuracy: 0.6438\n",
            "Epoch 5/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6288 - accuracy: 0.8469 - val_loss: 1.4468 - val_accuracy: 0.6969\n",
            "Epoch 6/25\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.7135 - accuracy: 0.8375 - val_loss: 1.8277 - val_accuracy: 0.6125\n",
            "Epoch 7/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6741 - accuracy: 0.8188 - val_loss: 1.8050 - val_accuracy: 0.6031\n",
            "Epoch 8/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6928 - accuracy: 0.8250 - val_loss: 1.7214 - val_accuracy: 0.6125\n",
            "Epoch 9/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6090 - accuracy: 0.8469 - val_loss: 1.7385 - val_accuracy: 0.6375\n",
            "Epoch 10/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6675 - accuracy: 0.8062 - val_loss: 1.7172 - val_accuracy: 0.6500\n",
            "Epoch 11/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5985 - accuracy: 0.8562 - val_loss: 1.5898 - val_accuracy: 0.6500\n",
            "Epoch 12/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6684 - accuracy: 0.8219 - val_loss: 1.6950 - val_accuracy: 0.6625\n",
            "Epoch 13/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5967 - accuracy: 0.8219 - val_loss: 1.5897 - val_accuracy: 0.6313\n",
            "Epoch 14/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5634 - accuracy: 0.8625 - val_loss: 1.7813 - val_accuracy: 0.6250\n",
            "Epoch 15/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5801 - accuracy: 0.8469 - val_loss: 1.8988 - val_accuracy: 0.5844\n",
            "Epoch 16/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.7029 - accuracy: 0.8219 - val_loss: 1.8193 - val_accuracy: 0.6125\n",
            "Epoch 17/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5261 - accuracy: 0.8719 - val_loss: 1.8092 - val_accuracy: 0.6156\n",
            "Epoch 18/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5415 - accuracy: 0.8344 - val_loss: 1.5107 - val_accuracy: 0.6750\n",
            "Epoch 19/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5898 - accuracy: 0.8531 - val_loss: 1.7849 - val_accuracy: 0.6125\n",
            "Epoch 20/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.4623 - accuracy: 0.8594 - val_loss: 1.5263 - val_accuracy: 0.6594\n",
            "Epoch 21/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.4655 - accuracy: 0.8719 - val_loss: 1.7052 - val_accuracy: 0.6344\n",
            "Epoch 22/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.4625 - accuracy: 0.8813 - val_loss: 1.3709 - val_accuracy: 0.7125\n",
            "Epoch 23/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5933 - accuracy: 0.8375 - val_loss: 1.5142 - val_accuracy: 0.6656\n",
            "Epoch 24/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5903 - accuracy: 0.8531 - val_loss: 1.5253 - val_accuracy: 0.6594\n",
            "Epoch 25/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5484 - accuracy: 0.8531 - val_loss: 1.7462 - val_accuracy: 0.6375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlj4kjeCGI5H"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3HjRa4OKvn-",
        "outputId": "8438ddec-4ed2-4e3e-9d4b-b1d985f2f3e5"
      },
      "source": [
        "with open('restnet50.pickle','wb') as f:\n",
        "  pickle.dump(model,f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://dcadfabc-d1a4-4440-9581-37e3d28cc7b2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        }
      ]
    }
  ]
}