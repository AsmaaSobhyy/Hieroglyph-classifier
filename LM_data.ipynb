{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "# from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gardiner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M17A26S34A1G43A1Z3N17N23A1Z2BS29V4X1S29N35D2Z1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W24V31V22F34N35M23X1N35G17R8O6X1O1Z1D21Z1O47Z1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G35F34F34F34D2Z1A17U6D21M17M17X1N23F20P28Z2G36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M17G43D4N35M17M40O34O1Z1G17V28W14X1O34M23X1N35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Gardiner\n",
       "0  D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4...\n",
       "1  M17A26S34A1G43A1Z3N17N23A1Z2BS29V4X1S29N35D2Z1...\n",
       "2  W24V31V22F34N35M23X1N35G17R8O6X1O1Z1D21Z1O47Z1...\n",
       "3  G35F34F34F34D2Z1A17U6D21M17M17X1N23F20P28Z2G36...\n",
       "4  M17G43D4N35M17M40O34O1Z1G17V28W14X1O34M23X1N35..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"GARDINERS_SENTENCES (1).csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4F29X1X1B1V30X1U23D58G43N25O49M17U1F39A1M17M17A1D21E16A40G39D21N35Q3G43X1Z3A1D4N35G39X1V13N35Z1M17B1I10D46'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Gardiner[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gardiner    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+\"train_2.pickle\", \"rb\") as f:\n",
    "    (X,y,sizes) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    sentences=[]\n",
    "    for sentence in data :\n",
    "        codes=[]\n",
    "        code=''\n",
    "        first_letter=False\n",
    "        for i in sentence:\n",
    "            if i.isupper() :\n",
    "                if first_letter:\n",
    "                    codes.append(code)\n",
    "                    code=''\n",
    "                else:\n",
    "                    first_letter=True\n",
    "            code+=i\n",
    "        codes.append(code)\n",
    "        sentences.append(codes)\n",
    "    return sentences\n",
    "sentences=tokenize(data.Gardiner[:])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input for the function : \n",
      "\n",
      " D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4F29X1X1B1V30X1U23D58G43N25O49M17U1F39A1M17M17A1D21E16A40G39D21N35Q3G43X1Z3A1D4N35G39X1V13N35Z1M17B1I10D46\n",
      "output : \n",
      "\n",
      " ['D21' 'Q3' 'D36' 'F4' 'D36' 'L2' 'X1' 'S19' 'S29' 'U23' 'T21' 'X1' 'G17'\n",
      " 'D21' 'Z1' 'R8' 'U36' 'S4' 'F29' 'X1' 'X1' 'B1' 'V30' 'X1' 'U23' 'D58'\n",
      " 'G43' 'N25' 'O49' 'M17' 'U1' 'F39' 'A1' 'M17' 'M17' 'A1' 'D21' 'E16'\n",
      " 'A40' 'G39' 'D21' 'N35' 'Q3' 'G43' 'X1' 'Z3' 'A1' 'D4' 'N35' 'G39' 'X1'\n",
      " 'V13' 'N35' 'Z1' 'M17' 'B1' 'I10' 'D46']\n"
     ]
    }
   ],
   "source": [
    "print(\"input for the function : \\n\\n\",data.Gardiner[0])\n",
    "print(\"output : \\n\\n\",np.array(sentences[0]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[0]\n",
    "all_codes=list(sizes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences=[]\n",
    "for sentence in sentences:\n",
    "    doesnt_exists=False\n",
    "    for code in sentence:\n",
    "        if code not in all_codes:\n",
    "            doesnt_exists=True\n",
    "    if doesnt_exists == False:\n",
    "        new_sentences.append(sentence)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2354"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=[]\n",
    "for sent in new_sentences:\n",
    "    if len(sent) > 2:\n",
    "        final_data.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1887"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G17', 'M17', 'U1', 'G43', 'G43']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data as pickle\n",
    "with open(\"lm_sentences.pickle\", \"wb\") as f:\n",
    "    pickle.dump((final_data),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,sentences,n=2):\n",
    "    # Count frequency of co-occurance\n",
    "    if n==3:\n",
    "        for sentence in sentences:\n",
    "            for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "                model[(w1, w2)][w3] += 1\n",
    "        # Let's transform the counts to probabilities\n",
    "        for w1_w2 in model:\n",
    "            total_count = float(sum(model[w1_w2].values()))\n",
    "            for w3 in model[w1_w2]:\n",
    "                model[w1_w2][w3] /= total_count\n",
    "    elif n==2:\n",
    "        #bigram\n",
    "        for sentence in sentences:\n",
    "            for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "                model[(w1)][w2] += 1\n",
    "        for w1_w2 in model:\n",
    "            total_count = float(sum(model[w1_w2].values()))\n",
    "            for w3 in model[w1_w2]:\n",
    "                model[w1_w2][w3] /= total_count\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_next(model,prev):\n",
    "    pred = dict( eval('model'+ str(prev)))\n",
    "    next_scores = sorted(pred.items(), key=lambda item: item[1],reverse=True)\n",
    "    out = dict(next_scores)\n",
    "    if len(list(out.keys()))==0:\n",
    "        out ={'None':0}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model,sentences,n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev=['X1' ,'N17'] \n",
    "# prediction=lm_next(model,prev)\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "with open(\"language_model_sent.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
