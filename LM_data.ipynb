{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "# from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gardiner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M17A26S34A1G43A1Z3N17N23A1Z2BS29V4X1S29N35D2Z1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W24V31V22F34N35M23X1N35G17R8O6X1O1Z1D21Z1O47Z1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G35F34F34F34D2Z1A17U6D21M17M17X1N23F20P28Z2G36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M17G43D4N35M17M40O34O1Z1G17V28W14X1O34M23X1N35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Gardiner\n",
       "0  D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4...\n",
       "1  M17A26S34A1G43A1Z3N17N23A1Z2BS29V4X1S29N35D2Z1...\n",
       "2  W24V31V22F34N35M23X1N35G17R8O6X1O1Z1D21Z1O47Z1...\n",
       "3  G35F34F34F34D2Z1A17U6D21M17M17X1N23F20P28Z2G36...\n",
       "4  M17G43D4N35M17M40O34O1Z1G17V28W14X1O34M23X1N35..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"GARDINERS_SENTENCES (1).csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D21Q3D36F4D36L2X1S19S29U23T21X1G17D21Z1R8U36S4F29X1X1B1V30X1U23D58G43N25O49M17U1F39A1M17M17A1D21E16A40G39D21N35Q3G43X1Z3A1D4N35G39X1V13N35Z1M17B1I10D46'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Gardiner[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gardiner    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+\"train.pickle\", \"rb\") as f:\n",
    "    (X,y,sizes) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "for sentence in data.Gardiner[:]:\n",
    "    codes=[]\n",
    "    code=''\n",
    "    first_letter=False\n",
    "    for i in sentence:\n",
    "        if i.isupper() :\n",
    "            if first_letter:\n",
    "                codes.append(code)\n",
    "                code=''\n",
    "            else:\n",
    "                first_letter=True\n",
    "        code+=i\n",
    "    sentences.append(codes)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[0]\n",
    "all_codes=list(sizes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences=[]\n",
    "for sentence in sentences:\n",
    "    doesnt_exists=False\n",
    "    for code in sentence:\n",
    "        if code not in all_codes:\n",
    "            doesnt_exists=True\n",
    "    if doesnt_exists == False:\n",
    "        new_sentences.append(sentence)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=[]\n",
    "for sent in new_sentences:\n",
    "    if len(sent) > 2:\n",
    "        final_data.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data as pickle\n",
    "with open(\"lm_sentences.pickle\", \"wb\") as f:\n",
    "    pickle.dump((final_data),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,sentences,n=2):\n",
    "    # Count frequency of co-occurance\n",
    "    if n==3:\n",
    "        for sentence in sentences:\n",
    "            for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "                model[(w1, w2)][w3] += 1\n",
    "        # Let's transform the counts to probabilities\n",
    "        for w1_w2 in model:\n",
    "            total_count = float(sum(model[w1_w2].values()))\n",
    "            for w3 in model[w1_w2]:\n",
    "                model[w1_w2][w3] /= total_count\n",
    "    elif n==2:\n",
    "        #bigram\n",
    "        for sentence in sentences:\n",
    "            for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "                model[(w1)][w2] += 1\n",
    "        for w1_w2 in model:\n",
    "            total_count = float(sum(model[w1_w2].values()))\n",
    "            for w3 in model[w1_w2]:\n",
    "                model[w1_w2][w3] /= total_count\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_next(model,prev):\n",
    "    pred = dict( eval('model'+ str(prev)))\n",
    "    next_scores = sorted(pred.items(), key=lambda item: item[1],reverse=True)\n",
    "    out = dict(next_scores)\n",
    "    if len(list(out.keys()))==0:\n",
    "        out ={'None':0}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model,sentences,n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev=['G1', 'G1'] \n",
    "prediction=lm_next(model,prev)\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "with open(\"language_model_sent.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
